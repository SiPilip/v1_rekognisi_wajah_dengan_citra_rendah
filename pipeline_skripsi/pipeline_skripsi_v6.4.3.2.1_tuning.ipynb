{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d44431c",
   "metadata": {},
   "source": [
    "svm_model = SVC(kernel='rbf', C=10.0, gamma='scale', probability=True)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='manhattan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb451e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Semua pustaka berhasil diimpor.\n",
      "Direktori telah disiapkan.\n",
      "Menggunakan device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 1: INISIALISASI & SETUP =============\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from deepface import DeepFace # Diperlukan untuk get_embedding gallery\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, f1_score, precision_score\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Semua pustaka berhasil diimpor.\")\n",
    "\n",
    "# Definisikan kelas Encoder kustom (jika diperlukan untuk menyimpan hasil baru)\n",
    "class NumpyJSONEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer): return int(obj)\n",
    "        elif isinstance(obj, np.floating): return float(obj)\n",
    "        elif isinstance(obj, np.ndarray): return obj.tolist()\n",
    "        elif isinstance(obj, np.bool_): return bool(obj)\n",
    "        else: return super(NumpyJSONEncoder, self).default(obj)\n",
    "\n",
    "# --- Konfigurasi Path ---\n",
    "BASE_DIR = os.path.abspath('.')\n",
    "GALLERY_PATH = os.path.join(BASE_DIR, 'data', 'gallery6.2') # Path galeri tetap diperlukan\n",
    "RESULTS_PATH = os.path.join(BASE_DIR, 'results_v6.4.3.2.1_recognition') # Path output analisis\n",
    "CACHE_PATH = os.path.join(BASE_DIR, 'cache_v6.4.3.2.1_recognition') # Path cache jika diperlukan\n",
    "# >>>>> PERUBAHAN PATH MODEL BARU <<<<<\n",
    "NEW_MODELS_PATH = os.path.join(BASE_DIR, 'models_v6.4.3.2.1_tuned') # Path BARU untuk menyimpan model hasil tuning\n",
    "PROBE_FEATURES_PATH = os.path.join(BASE_DIR, 'features_v6.4') # Path fitur probe dari v6.4\n",
    "\n",
    "# Pastikan semua direktori ada\n",
    "for path in [RESULTS_PATH, CACHE_PATH, NEW_MODELS_PATH]: # Tambahkan NEW_MODELS_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "print(\"Direktori telah disiapkan.\")\n",
    "\n",
    "# --- Setup Device ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Menggunakan device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea45974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi-fungsi utilitas siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 2: DEFINISI FUNGSI UTILITAS =============\n",
    "\n",
    "# Fungsi get_embedding diperlukan untuk melatih classifier dari galeri\n",
    "def get_embedding(image_path_or_array, model_name='ArcFace', detector_backend='retinaface') -> list | None:\n",
    "    \"\"\"Mengekstrak embedding wajah dari path gambar atau array (dengan deteksi).\"\"\"\n",
    "    try:\n",
    "        embedding_objs = DeepFace.represent(\n",
    "            img_path=image_path_or_array, model_name=model_name,\n",
    "            enforce_detection=True, detector_backend=detector_backend\n",
    "        )\n",
    "        if embedding_objs and isinstance(embedding_objs, list):\n",
    "            return embedding_objs[0]['embedding']\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error saat get_embedding: {e}\") # Uncomment untuk debug\n",
    "        return None\n",
    "\n",
    "# Fungsi Cosine Similarity diperlukan untuk perbandingan\n",
    "def cosine_similarity_prediction(query_embedding, gallery_embeddings, gallery_labels, threshold=0.5):\n",
    "    \"\"\"Prediksi menggunakan cosine similarity.\"\"\"\n",
    "    if query_embedding is None or not gallery_embeddings:\n",
    "        return \"unknown\", 0.0, False\n",
    "\n",
    "    query_embedding = np.array(query_embedding)\n",
    "    query_norm = np.linalg.norm(query_embedding)\n",
    "    if query_norm == 0:\n",
    "        return \"unknown\", 0.0, False\n",
    "    query_embedding = query_embedding / query_norm\n",
    "\n",
    "    similarities = []\n",
    "    valid_gallery_labels = []\n",
    "    for gallery_emb, label in zip(gallery_embeddings, gallery_labels):\n",
    "        gallery_emb = np.array(gallery_emb)\n",
    "        gallery_norm = np.linalg.norm(gallery_emb)\n",
    "        if gallery_norm > 0:\n",
    "            gallery_emb = gallery_emb / gallery_norm\n",
    "            similarity = np.dot(query_embedding, gallery_emb)\n",
    "            similarities.append(similarity)\n",
    "            valid_gallery_labels.append(label)\n",
    "\n",
    "    if not similarities:\n",
    "        return \"unknown\", 0.0, False\n",
    "\n",
    "    max_similarity = np.max(similarities)\n",
    "    max_idx = np.argmax(similarities)\n",
    "    predicted_label = valid_gallery_labels[max_idx]\n",
    "    is_recognized = max_similarity > threshold\n",
    "\n",
    "    if np.isnan(max_similarity):\n",
    "         return \"unknown\", 0.0, False\n",
    "\n",
    "    return predicted_label, float(max_similarity), bool(is_recognized)\n",
    "\n",
    "def cosine_similarity_top_n(query_embedding, gallery_embeddings, gallery_labels, top_n=5):\n",
    "    \"\"\"\n",
    "    Mengembalikan Top-N label beserta skor similarity-nya.\n",
    "    \"\"\"\n",
    "    if query_embedding is None or not gallery_embeddings:\n",
    "        return [], False\n",
    "\n",
    "    query_embedding = np.array(query_embedding)\n",
    "    query_norm = np.linalg.norm(query_embedding)\n",
    "    if query_norm == 0:\n",
    "        return [], False\n",
    "    query_embedding = query_embedding / query_norm\n",
    "\n",
    "    # Hitung similarity untuk semua kandidat di galeri\n",
    "    scores = []\n",
    "    for gallery_emb, label in zip(gallery_embeddings, gallery_labels):\n",
    "        gallery_emb = np.array(gallery_emb)\n",
    "        gallery_norm = np.linalg.norm(gallery_emb)\n",
    "        if gallery_norm > 0:\n",
    "            gallery_emb = gallery_emb / gallery_norm\n",
    "            sim = np.dot(query_embedding, gallery_emb)\n",
    "            scores.append((label, sim))\n",
    "\n",
    "    # Urutkan dari similarity terbesar ke terkecil\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Ambil Top-N\n",
    "    # Catatan: Ini logic \"Nearest Neighbor\". Jika ada banyak foto 'subject_a' di galeri,\n",
    "    # Top-5 bisa jadi ['a', 'a', 'a', 'b', 'c'].\n",
    "    # Jika ground_truth 'a' ada di list ini, maka hitungannya benar.\n",
    "    top_results = scores[:top_n]\n",
    "    \n",
    "    return top_results\n",
    "\n",
    "\n",
    "print(\"Fungsi-fungsi utilitas siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4a95e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Quality Assessment on: cpu\n",
      "Memuat model BRISQUE & NIQE... (Download otomatis jika belum ada)\n",
      "Model Kualitas Citra Siap.\n",
      "Fungsi perhitungan BRISQUE & NIQE (PyIQA) siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 3 (FIXED: PYIQA UNTUK NIQE & BRISQUE) =============\n",
    "import pyiqa\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Setup Device (Gunakan CUDA agar cepat)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running Quality Assessment on: {DEVICE}\")\n",
    "\n",
    "# Inisialisasi Model (Hanya sekali load agar tidak berat)\n",
    "try:\n",
    "    # Menggunakan PyIQA - Standar Penelitian CV\n",
    "    print(\"Memuat model BRISQUE & NIQE... (Download otomatis jika belum ada)\")\n",
    "    brisque_metric = pyiqa.create_metric('brisque', device=DEVICE, as_loss=False)\n",
    "    niqe_metric = pyiqa.create_metric('niqe', device=DEVICE, as_loss=False)\n",
    "    print(\"Model Kualitas Citra Siap.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR Inisialisasi PyIQA: {e}\")\n",
    "    brisque_metric = None\n",
    "    niqe_metric = None\n",
    "\n",
    "def calculate_image_quality(image_path):\n",
    "    \"\"\"\n",
    "    Menghitung skor BRISQUE & NIQE menggunakan PyIQA.\n",
    "    Input: Path gambar (String)\n",
    "    Output: Dictionary skor\n",
    "    \"\"\"\n",
    "    metrics = {'brisque': np.nan, 'niqe': np.nan}\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        return metrics\n",
    "        \n",
    "    try:\n",
    "        # PyIQA membutuhkan input Tensor (RGB, 0-1, bentuk BCHW)\n",
    "        # Kita pakai PIL untuk baca gambar agar formatnya benar (RGB)\n",
    "        img_pil = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Konversi ke Tensor\n",
    "        # PyIQA biasanya punya helper, tapi kita pakai manual agar aman:\n",
    "        img_tensor = torch.from_numpy(np.array(img_pil)).float() / 255.0\n",
    "        img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        # 1. Hitung BRISQUE (Lower is Better)\n",
    "        if brisque_metric is not None:\n",
    "            with torch.no_grad():\n",
    "                score = brisque_metric(img_tensor)\n",
    "                metrics['brisque'] = score.item()\n",
    "                \n",
    "        # 2. Hitung NIQE (Lower is Better)\n",
    "        if niqe_metric is not None:\n",
    "            with torch.no_grad():\n",
    "                score = niqe_metric(img_tensor)\n",
    "                metrics['niqe'] = score.item()\n",
    "                \n",
    "    except Exception as e:\n",
    "        # print(f\"Error calculating metrics for {image_path}: {e}\")\n",
    "        pass\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "print(\"Fungsi perhitungan BRISQUE & NIQE (PyIQA) siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd2dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi perhitungan BRISQUE & Blur Score siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# ============== TAMBAHAN: FUNGSI KUALITAS CITRA (BRISQUE & NIQE) =============\n",
    "from brisque import BRISQUE\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Inisialisasi obyek BRISQUE\n",
    "# Note: Jika ini pertama kali dijalankan, ia mungkin akan mendownload model kecil\n",
    "try:\n",
    "    brisque_obj = BRISQUE(url=False)\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Gagal inisialisasi BRISQUE. Pastikan 'pip install brisque' sukses. Error: {e}\")\n",
    "    brisque_obj = None\n",
    "\n",
    "def calculate_blur_score(image):\n",
    "    \"\"\"\n",
    "    Menghitung skor ketajaman menggunakan Variance of Laplacian.\n",
    "    Makin TINGGI nilainya, makin TAJAM gambarnya.\n",
    "    Makin RENDAH (< 100), makin BLUR gambarnya.\n",
    "    \"\"\"\n",
    "    if image is None: return 0.0\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    score = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    return score\n",
    "\n",
    "def calculate_image_quality(image_path):\n",
    "    \"\"\"\n",
    "    Menghitung skor BRISQUE (Naturalness) dan Blur Score (Sharpness).\n",
    "    \"\"\"\n",
    "    metrics = {'brisque': np.nan, 'blur_score': np.nan}\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "            return metrics\n",
    "            \n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return metrics\n",
    "            \n",
    "        # 1. Hitung BRISQUE (Lower is Better: 0=Best, 100=Worst)\n",
    "        if brisque_obj is not None:\n",
    "            try:\n",
    "                metrics['brisque'] = brisque_obj.score(img)\n",
    "            except Exception:\n",
    "                metrics['brisque'] = np.nan\n",
    "        \n",
    "        # 2. Hitung Blur Score / Sharpness (Higher is Better)\n",
    "        # Ini menggantikan NIQE. Sangat bagus untuk analisis jarak jauh.\n",
    "        try:\n",
    "            metrics['blur_score'] = calculate_blur_score(img)\n",
    "        except Exception:\n",
    "            metrics['blur_score'] = np.nan\n",
    "            \n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "print(\"Fungsi perhitungan BRISQUE & Blur Score siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a51f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ISI FOLDER REAL (1364 file) ---\n",
      "Contoh 3 file di folder: ['a_gp_0_ef_00.jpg', 'a_gp_0_ef_01.jpg', 'a_gp_0_ef_02.jpg']\n",
      "\n",
      "--- ISI JSON (1364 data) ---\n",
      "Contoh path di JSON (Raw): a_gp_0_ef_00.jpg\n",
      "Contoh filename di JSON (Base): a_gp_0_ef_00.jpg\n",
      "\n",
      "[OK] File 'a_gp_0_ef_00.jpg' DITEMUKAN di folder!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Path folder Anda (dari screenshot)\n",
    "DIR_ORIGINAL = r\"D:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4_extraction\\cropped_faces\"\n",
    "DIR_RESTORED = r\"D:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4_extraction\\restored_faces\"\n",
    "\n",
    "# Path JSON\n",
    "PROBE_FEATURES_PATH = r\"D:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\features_v6.4\"\n",
    "features_file = os.path.join(PROBE_FEATURES_PATH, 'probe_features_v6.4.json')\n",
    "\n",
    "# 1. Cek isi folder fisik\n",
    "files_in_folder = os.listdir(DIR_ORIGINAL)\n",
    "print(f\"--- ISI FOLDER REAL ({len(files_in_folder)} file) ---\")\n",
    "print(f\"Contoh 3 file di folder: {files_in_folder[:3]}\")\n",
    "\n",
    "# 2. Cek isi JSON\n",
    "with open(features_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"\\n--- ISI JSON ({len(data)} data) ---\")\n",
    "sample_json = data[0]['file']\n",
    "print(f\"Contoh path di JSON (Raw): {sample_json}\")\n",
    "print(f\"Contoh filename di JSON (Base): {os.path.basename(sample_json)}\")\n",
    "\n",
    "# 3. Cek Kecocokan\n",
    "json_filename = os.path.basename(sample_json)\n",
    "if json_filename in files_in_folder:\n",
    "    print(f\"\\n[OK] File '{json_filename}' DITEMUKAN di folder!\")\n",
    "else:\n",
    "    print(f\"\\n[ERROR] File '{json_filename}' TIDAK DITEMUKAN di folder.\")\n",
    "    print(\"Kemungkinan nama file beda atau ekstensi beda.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e5bf3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat ulang semua model...\n",
      "[OK] KNN, SVM, LabelEncoder dimuat.\n",
      "[OK] Gallery Embeddings dimuat (55 data).\n",
      "Mengindeks file gambar...\n",
      "\n",
      "Memulai Analisis Lengkap...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c652a7df33447ca096f80351272457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai. Data siap untuk Langkah 5.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 4 (FINAL FIX): REKOGNISI LENGKAP (KNN, SVM, COSINE) + KUALITAS =============\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- 1. KONFIGURASI PATH ---\n",
    "BASE_IMG_DIR = r\"D:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4_extraction\"\n",
    "DIR_ORIGINAL = os.path.join(BASE_IMG_DIR, \"cropped_faces\")\n",
    "DIR_RESTORED = os.path.join(BASE_IMG_DIR, \"restored_faces\")\n",
    "NEW_MODELS_PATH = os.path.join(BASE_DIR, 'models_v6.4.3.2_tuned')\n",
    "CACHE_PATH = os.path.join(BASE_DIR, 'cache_v6.4.3.2_recognition')\n",
    "\n",
    "# --- 2. RELOAD SEMUA MODEL (KNN, SVM, LE, GALLERY) ---\n",
    "print(\"Memuat ulang semua model...\")\n",
    "try:\n",
    "    with open(os.path.join(NEW_MODELS_PATH, 'knn_model_tuned.pkl'), 'rb') as f: knn_model = pickle.load(f)\n",
    "    with open(os.path.join(NEW_MODELS_PATH, 'svm_model_tuned.pkl'), 'rb') as f: svm_model = pickle.load(f)\n",
    "    with open(os.path.join(NEW_MODELS_PATH, 'label_encoder.pkl'), 'rb') as f: le = pickle.load(f)\n",
    "    print(\"[OK] KNN, SVM, LabelEncoder dimuat.\")\n",
    "    \n",
    "    # Load Gallery untuk Cosine\n",
    "    with open(os.path.join(CACHE_PATH, 'gallery_embeddings_cache.pkl'), 'rb') as f:\n",
    "        gallery_embeddings, gallery_labels = pickle.load(f)\n",
    "    print(f\"[OK] Gallery Embeddings dimuat ({len(gallery_embeddings)} data).\")\n",
    "except Exception as e:\n",
    "    print(f\"[CRITICAL ERROR] Gagal load model: {e}\")\n",
    "    raise e\n",
    "\n",
    "# --- 3. SETUP MODEL KUALITAS (BRISQUE & NIQE) ---\n",
    "try:\n",
    "    from brisque import BRISQUE\n",
    "    brisque_obj = BRISQUE(url=False)\n",
    "except: brisque_obj = None\n",
    "\n",
    "try:\n",
    "    import pyiqa\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    niqe_metric = pyiqa.create_metric('niqe', device=DEVICE, as_loss=False)\n",
    "except: niqe_metric = None\n",
    "\n",
    "# --- 4. INDEXING GAMBAR (Agar Cepat) ---\n",
    "print(\"Mengindeks file gambar...\")\n",
    "orig_files_map = {f: os.path.join(DIR_ORIGINAL, f) for f in os.listdir(DIR_ORIGINAL) if f.lower().endswith(('.jpg', '.png'))}\n",
    "rest_files_map = {f: os.path.join(DIR_RESTORED, f) for f in os.listdir(DIR_RESTORED) if f.lower().endswith(('.jpg', '.png'))}\n",
    "\n",
    "# --- 5. FUNGSI HITUNG KUALITAS ---\n",
    "def get_hybrid_scores(path):\n",
    "    res = {'brisque': np.nan, 'niqe': np.nan}\n",
    "    if not path or not os.path.exists(path): return res\n",
    "    # BRISQUE\n",
    "    if brisque_obj:\n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            if img is not None: res['brisque'] = brisque_obj.score(img)\n",
    "        except: pass\n",
    "    # NIQE\n",
    "    if niqe_metric:\n",
    "        try:\n",
    "            img_pil = Image.open(path).convert('RGB')\n",
    "            t = torch.from_numpy(np.array(img_pil)).float() / 255.0\n",
    "            t = t.permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n",
    "            with torch.no_grad(): res['niqe'] = niqe_metric(t).item()\n",
    "        except: pass\n",
    "    return res\n",
    "\n",
    "# --- 6. FUNGSI PREDIKSI KOMPLIT (KNN, SVM, COSINE) ---\n",
    "def predict_all_algorithms(embedding, ground_truth):\n",
    "    # Default Result jika embedding kosong\n",
    "    res = {\n",
    "        'knn_top1': False, 'prediction_knn': 'unknown',\n",
    "        'svm_top1': False, 'prediction_svm': 'unknown',\n",
    "        'cosine_top1': False, 'prediction_cosine': 'unknown',\n",
    "        'embedding_found': False\n",
    "    }\n",
    "    \n",
    "    if not isinstance(embedding, list) or len(embedding) == 0: return res\n",
    "    res['embedding_found'] = True\n",
    "    \n",
    "    try:\n",
    "        emb_np = np.array(embedding).reshape(1, -1)\n",
    "        \n",
    "        # A. KNN\n",
    "        pred_idx = knn_model.predict(emb_np)[0]\n",
    "        pred_label = le.inverse_transform([pred_idx])[0]\n",
    "        res['prediction_knn'] = pred_label\n",
    "        res['knn_top1'] = (pred_label == ground_truth)\n",
    "        \n",
    "        # B. SVM\n",
    "        pred_idx_svm = svm_model.predict(emb_np)[0]\n",
    "        pred_label_svm = le.inverse_transform([pred_idx_svm])[0]\n",
    "        res['prediction_svm'] = pred_label_svm\n",
    "        res['svm_top1'] = (pred_label_svm == ground_truth)\n",
    "        \n",
    "        # C. COSINE SIMILARITY\n",
    "        # Hitung similarity dengan semua gallery\n",
    "        sims = cosine_similarity(emb_np, np.array(gallery_embeddings))[0]\n",
    "        best_idx = np.argmax(sims)\n",
    "        pred_label_cos = gallery_labels[best_idx]\n",
    "        res['prediction_cosine'] = pred_label_cos\n",
    "        res['cosine_top1'] = (pred_label_cos == ground_truth)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(f\"Error prediction: {e}\")\n",
    "        pass\n",
    "        \n",
    "    return res\n",
    "\n",
    "# --- 7. LOOP UTAMA ---\n",
    "features_path = os.path.join(PROBE_FEATURES_PATH, 'probe_features_v6.4.json')\n",
    "with open(features_path, 'r') as f: probe_features = json.load(f)\n",
    "\n",
    "recognition_results = []\n",
    "\n",
    "print(\"\\nMemulai Analisis Lengkap...\")\n",
    "for entry in tqdm(probe_features):\n",
    "    fname = os.path.basename(entry.get('file', ''))\n",
    "    ground_truth = entry.get('ground_truth', 'unknown')\n",
    "    \n",
    "    # 1. Cari File & Hitung Quality\n",
    "    p_orig = orig_files_map.get(fname)\n",
    "    p_rest = rest_files_map.get(fname)\n",
    "    \n",
    "    s_orig = get_hybrid_scores(p_orig)\n",
    "    s_rest = get_hybrid_scores(p_rest)\n",
    "    \n",
    "    # 2. Prediksi Semua Algoritma\n",
    "    res_orig = predict_all_algorithms(entry.get('embedding_original'), ground_truth)\n",
    "    res_rest = predict_all_algorithms(entry.get('embedding_restored'), ground_truth)\n",
    "    \n",
    "    # 3. Susun Hasil Akhir (Flatten dictionary agar mudah dibaca pandas)\n",
    "    final_res = {\n",
    "        'file': fname,\n",
    "        'metadata': entry.get('metadata', {}),\n",
    "        'ground_truth': ground_truth,\n",
    "        \n",
    "        # Quality\n",
    "        'brisque_original': s_orig['brisque'], 'niqe_original': s_orig['niqe'],\n",
    "        'brisque_restored': s_rest['brisque'], 'niqe_restored': s_rest['niqe'],\n",
    "        \n",
    "        # Original Predictions\n",
    "        'embedding_original_found': res_orig['embedding_found'],\n",
    "        'knn_top1_original': res_orig['knn_top1'],\n",
    "        'prediction_knn_original': res_orig['prediction_knn'], # <--- INI YG HILANG TADI\n",
    "        'svm_top1_original': res_orig['svm_top1'],\n",
    "        'prediction_svm_original': res_orig['prediction_svm'],\n",
    "        'cosine_top1_original': res_orig['cosine_top1'],\n",
    "        'prediction_cosine_original': res_orig['prediction_cosine'],\n",
    "        \n",
    "        # Restored Predictions\n",
    "        'embedding_restored_found': res_rest['embedding_found'],\n",
    "        'knn_top1_restored': res_rest['knn_top1'],\n",
    "        'prediction_knn_restored': res_rest['prediction_knn'], # <--- INI JUGA\n",
    "        'svm_top1_restored': res_rest['svm_top1'],\n",
    "        'prediction_svm_restored': res_rest['prediction_svm'],\n",
    "        'cosine_top1_restored': res_rest['cosine_top1'],\n",
    "        'prediction_cosine_restored': res_rest['prediction_cosine']\n",
    "    }\n",
    "    recognition_results.append(final_res)\n",
    "\n",
    "print(\"Selesai. Data siap untuk Langkah 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "367660ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "             ANALISIS PERBANDINGAN: KUALITAS CITRA (BRISQUE/NIQE) vs AKURASI REKOGNISI              \n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "==============================================================================================================\n",
      "                                    TABEL HASIL: K-Nearest Neighbors (KNN)                                    \n",
      "==============================================================================================================\n",
      "              Skenario   Metode Avg BRISQUE Avg NIQE Akurasi F1-Score Improvement\n",
      "    Jarak Dekat (< 7m) Original        3.91     4.27  84.10%   85.09%           -\n",
      "                       Restored        3.90     4.26  77.27%   79.91%      -8.12%\n",
      "Jarak Menengah (7-12m) Original        1.69     4.26  56.04%   59.73%           -\n",
      "                       Restored        1.70     4.26  72.95%   72.48%     +30.19%\n",
      "   Jarak Jauh (>= 12m) Original        3.78     4.09  11.30%    5.48%           -\n",
      "                       Restored        3.69     4.09  41.53%   39.57%    +267.61%\n",
      "       Ketinggian 1.5m Original        8.81     4.53  58.82%   65.67%           -\n",
      "                       Restored        8.81     4.53  65.69%   66.30%     +11.67%\n",
      "         Ketinggian 3m Original        4.54     4.41  57.23%   63.21%           -\n",
      "                       Restored        4.46     4.41  70.38%   70.91%     +22.99%\n",
      "         Ketinggian 4m Original        0.19     4.09  49.12%   54.75%           -\n",
      "                       Restored        0.21     4.09  68.62%   68.92%     +39.71%\n",
      "         Ketinggian 5m Original       -1.06     3.78  31.33%   33.61%           -\n",
      "                       Restored       -1.02     3.77  48.09%   48.17%     +53.53%\n",
      "        Semua Data Uji Original        3.14     4.20  49.22%   55.60%           -\n",
      "                       Restored        3.12     4.20  63.20%   64.28%     +28.39%\n",
      "[Info] Tabel disimpan ke: final_analysis_knn_with_quality.csv\n",
      "\n",
      "==============================================================================================================\n",
      "                                  TABEL HASIL: Support Vector Machine (SVM)                                   \n",
      "==============================================================================================================\n",
      "              Skenario   Metode Avg BRISQUE Avg NIQE Akurasi F1-Score Improvement\n",
      "    Jarak Dekat (< 7m) Original        3.91     4.27  85.48%   86.01%           -\n",
      "                       Restored        3.90     4.26  77.27%   79.52%      -9.61%\n",
      "Jarak Menengah (7-12m) Original        1.69     4.26  55.58%   57.78%           -\n",
      "                       Restored        1.70     4.26  73.64%   72.60%     +32.49%\n",
      "   Jarak Jauh (>= 12m) Original        3.78     4.09  10.67%    3.92%           -\n",
      "                       Restored        3.69     4.09  39.88%   37.76%    +273.74%\n",
      "       Ketinggian 1.5m Original        8.81     4.53  58.24%   64.30%           -\n",
      "                       Restored        8.81     4.53  65.69%   66.24%     +12.80%\n",
      "         Ketinggian 3m Original        4.54     4.41  57.82%   62.56%           -\n",
      "                       Restored        4.46     4.41  71.26%   71.37%     +23.25%\n",
      "         Ketinggian 4m Original        0.19     4.09  51.47%   56.65%           -\n",
      "                       Restored        0.21     4.09  67.16%   66.98%     +30.47%\n",
      "         Ketinggian 5m Original       -1.06     3.78  29.22%   29.99%           -\n",
      "                       Restored       -1.02     3.77  47.21%   45.97%     +61.60%\n",
      "        Semua Data Uji Original        3.14     4.20  49.30%   54.64%           -\n",
      "                       Restored        3.12     4.20  62.83%   63.42%     +27.45%\n",
      "[Info] Tabel disimpan ke: final_analysis_svm_with_quality.csv\n",
      "\n",
      "==============================================================================================================\n",
      "                                        TABEL HASIL: Cosine Similarity                                        \n",
      "==============================================================================================================\n",
      "              Skenario   Metode Avg BRISQUE Avg NIQE Akurasi F1-Score Improvement\n",
      "    Jarak Dekat (< 7m) Original        3.91     4.27  89.40%   89.69%           -\n",
      "                       Restored        3.90     4.26  78.64%   81.32%     -12.04%\n",
      "Jarak Menengah (7-12m) Original        1.69     4.26  65.15%   67.54%           -\n",
      "                       Restored        1.70     4.26  76.59%   76.92%     +17.56%\n",
      "   Jarak Jauh (>= 12m) Original        3.78     4.09  15.06%   11.03%           -\n",
      "                       Restored        3.69     4.09  45.66%   44.92%    +203.14%\n",
      "       Ketinggian 1.5m Original        8.81     4.53  62.35%   68.12%           -\n",
      "                       Restored        8.81     4.53  69.21%   69.55%     +10.99%\n",
      "         Ketinggian 3m Original        4.54     4.41  63.72%   68.28%           -\n",
      "                       Restored        4.46     4.41  77.13%   77.26%     +21.05%\n",
      "         Ketinggian 4m Original        0.19     4.09  54.71%   59.68%           -\n",
      "                       Restored        0.21     4.09  72.14%   72.18%     +31.87%\n",
      "         Ketinggian 5m Original       -1.06     3.78  39.76%   42.13%           -\n",
      "                       Restored       -1.02     3.77  46.63%   46.21%     +17.28%\n",
      "        Semua Data Uji Original        3.14     4.20  55.22%   60.86%           -\n",
      "                       Restored        3.12     4.20  66.28%   66.92%     +20.02%\n",
      "[Info] Tabel disimpan ke: final_analysis_cosine_with_quality.csv\n",
      "\n",
      "====================================================================================================\n",
      "                                          ANALISIS SELESAI                                          \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 5 (FINAL): ANALISIS PERBANDINGAN AKURASI vs KUALITAS CITRA =============\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Pastikan ada data\n",
    "if not recognition_results:\n",
    "    print(\"\\n[WARNING] Tidak ada hasil rekognisi untuk dianalisis.\")\n",
    "else:\n",
    "    df_results = pd.DataFrame(recognition_results)\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"ANALISIS PERBANDINGAN: KUALITAS CITRA (BRISQUE/NIQE) vs AKURASI REKOGNISI\".center(100))\n",
    "    print(f\"{'='*100}\\n\")\n",
    "\n",
    "    # Filter Data Valid (yang punya embedding)\n",
    "    df_original = df_results[df_results['embedding_original_found'] == True].copy()\n",
    "    df_restored = df_results[df_results['embedding_restored_found'] == True].copy()\n",
    "\n",
    "    # Ekstrak Metadata Jarak & Tinggi\n",
    "    for df in [df_original, df_restored]:\n",
    "        if not df.empty:\n",
    "            df['distance_m'] = df['metadata'].apply(lambda x: x.get('distance_m'))\n",
    "            df['height_m'] = df['metadata'].apply(lambda x: x.get('height_m'))\n",
    "\n",
    "    # --- FUNGSI HELPER HITUNG METRIK ---\n",
    "    def get_summary_stats(df, suffix, model_key, labels_list):\n",
    "        stats = {}\n",
    "        \n",
    "        # 1. Hitung Rata-rata Kualitas Citra (Tahan terhadap NaN)\n",
    "        stats['avg_brisque'] = df[f'brisque{suffix}'].mean() if f'brisque{suffix}' in df.columns else 0\n",
    "        stats['avg_niqe'] = df[f'niqe{suffix}'].mean() if f'niqe{suffix}' in df.columns else 0\n",
    "        \n",
    "        # 2. Hitung Metrik Rekognisi\n",
    "        col_pred = f'prediction_{model_key}{suffix}'\n",
    "        # Logic Top-1 Accuracy (sesuai output Step 4 sebelumnya yang menyimpan boolean)\n",
    "        col_correct = f'{model_key}_top1{suffix}' \n",
    "        \n",
    "        if col_correct in df.columns:\n",
    "            stats['accuracy'] = df[col_correct].mean()\n",
    "            \n",
    "            # Hitung F1 Score Macro\n",
    "            y_true = df['ground_truth']\n",
    "            y_pred = df[col_pred]\n",
    "            stats['f1'] = f1_score(y_true, y_pred, average='macro', zero_division=0, labels=labels_list)\n",
    "        else:\n",
    "            stats['accuracy'] = 0\n",
    "            stats['f1'] = 0\n",
    "            \n",
    "        return stats\n",
    "\n",
    "    # --- DEFINISI SKENARIO PENGUJIAN ---\n",
    "    scenarios = [\n",
    "        {\"name\": \"Jarak Dekat (< 7m)\", \"col\": \"distance_m\", \"cond\": lambda x: x < 7},\n",
    "        {\"name\": \"Jarak Menengah (7-12m)\", \"col\": \"distance_m\", \"cond\": lambda x: 7 <= x < 12},\n",
    "        {\"name\": \"Jarak Jauh (>= 12m)\", \"col\": \"distance_m\", \"cond\": lambda x: x >= 12},\n",
    "        {\"name\": \"Ketinggian 1.5m\", \"col\": \"height_m\", \"cond\": lambda x: x == 1.5},\n",
    "        {\"name\": \"Ketinggian 3m\", \"col\": \"height_m\", \"cond\": lambda x: x == 3},\n",
    "        {\"name\": \"Ketinggian 4m\", \"col\": \"height_m\", \"cond\": lambda x: x == 4},\n",
    "        {\"name\": \"Ketinggian 5m\", \"col\": \"height_m\", \"cond\": lambda x: x == 5},\n",
    "        {\"name\": \"Semua Data Uji\", \"col\": None, \"cond\": None}\n",
    "    ]\n",
    "\n",
    "    models = [\n",
    "        ('knn', 'K-Nearest Neighbors (KNN)'),\n",
    "        ('svm', 'Support Vector Machine (SVM)'),\n",
    "        ('cosine', 'Cosine Similarity')\n",
    "    ]\n",
    "\n",
    "    # --- LOOP UTAMA PEMBUATAN TABEL ---\n",
    "    for model_key, model_name in models:\n",
    "        table_rows = []\n",
    "        \n",
    "        for sc in scenarios:\n",
    "            # Filter Data per Skenario\n",
    "            if sc['col']:\n",
    "                d_orig = df_original[df_original[sc['col']].apply(sc['cond'])]\n",
    "                d_rest = df_restored[df_restored[sc['col']].apply(sc['cond'])]\n",
    "            else:\n",
    "                d_orig = df_original\n",
    "                d_rest = df_restored\n",
    "            \n",
    "            # Ambil semua label unik di skenario ini untuk perhitungan F1\n",
    "            all_labels = sorted(set(d_orig['ground_truth'].unique()) | set(d_rest['ground_truth'].unique()))\n",
    "            \n",
    "            # --- BARIS 1: ORIGINAL ---\n",
    "            if not d_orig.empty:\n",
    "                s = get_summary_stats(d_orig, '_original', model_key, all_labels)\n",
    "                table_rows.append({\n",
    "                    'Skenario': sc['name'],\n",
    "                    'Metode': 'Original',\n",
    "                    'Avg BRISQUE': s['avg_brisque'],\n",
    "                    'Avg NIQE': s['avg_niqe'],\n",
    "                    'Akurasi': s['accuracy'],\n",
    "                    'F1-Score': s['f1'],\n",
    "                    'Improvement': '-'\n",
    "                })\n",
    "            else:\n",
    "                table_rows.append({'Skenario': sc['name'], 'Metode': 'Original', 'Akurasi': 0, 'Improvement': '-'})\n",
    "\n",
    "            # --- BARIS 2: RESTORED ---\n",
    "            if not d_rest.empty:\n",
    "                s_res = get_summary_stats(d_rest, '_restored', model_key, all_labels)\n",
    "                \n",
    "                # Hitung Peningkatan Akurasi\n",
    "                imp_str = \"-\"\n",
    "                if not d_orig.empty:\n",
    "                    acc_orig = get_summary_stats(d_orig, '_original', model_key, all_labels)['accuracy']\n",
    "                    if acc_orig > 0:\n",
    "                        imp = ((s_res['accuracy'] - acc_orig) / acc_orig) * 100\n",
    "                        imp_str = f\"{imp:+.2f}%\"\n",
    "                \n",
    "                table_rows.append({\n",
    "                    'Skenario': '', # Kosongkan nama skenario biar rapi (grouped view)\n",
    "                    'Metode': 'Restored',\n",
    "                    'Avg BRISQUE': s_res['avg_brisque'],\n",
    "                    'Avg NIQE': s_res['avg_niqe'],\n",
    "                    'Akurasi': s_res['accuracy'],\n",
    "                    'F1-Score': s_res['f1'],\n",
    "                    'Improvement': imp_str\n",
    "                })\n",
    "            else:\n",
    "                 table_rows.append({'Skenario': '', 'Metode': 'Restored', 'Akurasi': 0, 'Improvement': '-'})\n",
    "\n",
    "        # --- BUAT DATAFRAME TABEL ---\n",
    "        df_table = pd.DataFrame(table_rows)\n",
    "        \n",
    "        # Format Kolom Angka agar Cantik\n",
    "        # Menggunakan .map agar tidak error jika ada data non-numeric/NaN\n",
    "        df_table['Avg BRISQUE'] = df_table['Avg BRISQUE'].map(lambda x: f\"{x:.2f}\" if pd.notnull(x) and isinstance(x, (int, float)) else \"-\")\n",
    "        df_table['Avg NIQE'] = df_table['Avg NIQE'].map(lambda x: f\"{x:.2f}\" if pd.notnull(x) and isinstance(x, (int, float)) else \"-\")\n",
    "        df_table['Akurasi'] = df_table['Akurasi'].map(lambda x: f\"{x:.2%}\" if pd.notnull(x) and isinstance(x, (int, float)) else \"0.00%\")\n",
    "        df_table['F1-Score'] = df_table['F1-Score'].map(lambda x: f\"{x:.2%}\" if pd.notnull(x) and isinstance(x, (int, float)) else \"0.00%\")\n",
    "        \n",
    "        # Reorder Columns\n",
    "        cols = ['Skenario', 'Metode', 'Avg BRISQUE', 'Avg NIQE', 'Akurasi', 'F1-Score', 'Improvement']\n",
    "        df_table = df_table[cols]\n",
    "        \n",
    "        # PRINT TABEL\n",
    "        print(f\"\\n{'='*110}\")\n",
    "        print(f\"TABEL HASIL: {model_name}\".center(110))\n",
    "        print(f\"{'='*110}\")\n",
    "        print(df_table.to_string(index=False))\n",
    "        \n",
    "        # Simpan ke CSV\n",
    "        csv_name = f\"final_analysis_{model_key}_with_quality.csv\"\n",
    "        df_table.to_csv(os.path.join(RESULTS_PATH, csv_name), index=False)\n",
    "        print(f\"[Info] Tabel disimpan ke: {csv_name}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ANALISIS SELESAI\".center(100))\n",
    "print(f\"{'='*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
