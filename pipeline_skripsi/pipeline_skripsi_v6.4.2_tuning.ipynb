{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d44431c",
   "metadata": {},
   "source": [
    "svm_model = SVC(kernel='rbf', C=10.0, gamma='scale', probability=True)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='manhattan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb451e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Semua pustaka berhasil diimpor.\n",
      "Direktori telah disiapkan.\n",
      "Menggunakan device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 1: INISIALISASI & SETUP =============\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from deepface import DeepFace # Diperlukan untuk get_embedding gallery\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Semua pustaka berhasil diimpor.\")\n",
    "\n",
    "# Definisikan kelas Encoder kustom (jika diperlukan untuk menyimpan hasil baru)\n",
    "class NumpyJSONEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer): return int(obj)\n",
    "        elif isinstance(obj, np.floating): return float(obj)\n",
    "        elif isinstance(obj, np.ndarray): return obj.tolist()\n",
    "        elif isinstance(obj, np.bool_): return bool(obj)\n",
    "        else: return super(NumpyJSONEncoder, self).default(obj)\n",
    "\n",
    "# --- Konfigurasi Path ---\n",
    "BASE_DIR = os.path.abspath('.')\n",
    "GALLERY_PATH = os.path.join(BASE_DIR, 'data', 'gallery6.2') # Path galeri tetap diperlukan\n",
    "RESULTS_PATH = os.path.join(BASE_DIR, 'results_v6.4.2_recognition') # Path output analisis\n",
    "CACHE_PATH = os.path.join(BASE_DIR, 'cache_v6.4.2_recognition') # Path cache jika diperlukan\n",
    "# >>>>> PERUBAHAN PATH MODEL BARU <<<<<\n",
    "NEW_MODELS_PATH = os.path.join(BASE_DIR, 'models_v6.4.2_tuned') # Path BARU untuk menyimpan model hasil tuning\n",
    "PROBE_FEATURES_PATH = os.path.join(BASE_DIR, 'features_v6.4') # Path fitur probe dari v6.4\n",
    "\n",
    "# Pastikan semua direktori ada\n",
    "for path in [RESULTS_PATH, CACHE_PATH, NEW_MODELS_PATH]: # Tambahkan NEW_MODELS_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "print(\"Direktori telah disiapkan.\")\n",
    "\n",
    "# --- Setup Device ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Menggunakan device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea45974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi-fungsi utilitas siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 2: DEFINISI FUNGSI UTILITAS =============\n",
    "\n",
    "# Fungsi get_embedding diperlukan untuk melatih classifier dari galeri\n",
    "def get_embedding(image_path_or_array, model_name='ArcFace', detector_backend='retinaface') -> list | None:\n",
    "    \"\"\"Mengekstrak embedding wajah dari path gambar atau array (dengan deteksi).\"\"\"\n",
    "    try:\n",
    "        embedding_objs = DeepFace.represent(\n",
    "            img_path=image_path_or_array, model_name=model_name,\n",
    "            enforce_detection=True, detector_backend=detector_backend\n",
    "        )\n",
    "        if embedding_objs and isinstance(embedding_objs, list):\n",
    "            return embedding_objs[0]['embedding']\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error saat get_embedding: {e}\") # Uncomment untuk debug\n",
    "        return None\n",
    "\n",
    "# Fungsi Cosine Similarity diperlukan untuk perbandingan\n",
    "def cosine_similarity_prediction(query_embedding, gallery_embeddings, gallery_labels, threshold=0.5):\n",
    "    \"\"\"Prediksi menggunakan cosine similarity.\"\"\"\n",
    "    if query_embedding is None or not gallery_embeddings:\n",
    "        return \"unknown\", 0.0, False\n",
    "\n",
    "    query_embedding = np.array(query_embedding)\n",
    "    query_norm = np.linalg.norm(query_embedding)\n",
    "    if query_norm == 0:\n",
    "        return \"unknown\", 0.0, False\n",
    "    query_embedding = query_embedding / query_norm\n",
    "\n",
    "    similarities = []\n",
    "    valid_gallery_labels = []\n",
    "    for gallery_emb, label in zip(gallery_embeddings, gallery_labels):\n",
    "        gallery_emb = np.array(gallery_emb)\n",
    "        gallery_norm = np.linalg.norm(gallery_emb)\n",
    "        if gallery_norm > 0:\n",
    "            gallery_emb = gallery_emb / gallery_norm\n",
    "            similarity = np.dot(query_embedding, gallery_emb)\n",
    "            similarities.append(similarity)\n",
    "            valid_gallery_labels.append(label)\n",
    "\n",
    "    if not similarities:\n",
    "        return \"unknown\", 0.0, False\n",
    "\n",
    "    max_similarity = np.max(similarities)\n",
    "    max_idx = np.argmax(similarities)\n",
    "    predicted_label = valid_gallery_labels[max_idx]\n",
    "    is_recognized = max_similarity > threshold\n",
    "\n",
    "    if np.isnan(max_similarity):\n",
    "         return \"unknown\", 0.0, False\n",
    "\n",
    "    return predicted_label, float(max_similarity), bool(is_recognized)\n",
    "\n",
    "\n",
    "print(\"Fungsi-fungsi utilitas siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4a95e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mempersiapkan data latih dari galeri...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f97163bee0b49ce9533f88ae1c06d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Membangun Dataset Latih:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset latih siap dengan 55 sampel.\n",
      "Subjek yang ditemukan: ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k']\n",
      "\n",
      "Melatih model K-Nearest Neighbors (KNN)...\n",
      "Model KNN selesai dilatih.\n",
      "Melatih model Support Vector Machine (SVM)...\n",
      "Model SVM selesai dilatih.\n",
      "Model KNN, SVM, dan LabelEncoder baru berhasil disimpan di: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\models_v6.4.2_tuned\n",
      "\n",
      "Mempersiapkan gallery embeddings untuk cosine similarity...\n",
      "Cache gallery embeddings tidak ditemukan, membuat ulang...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ba1c295665494f9ed2695464b0f9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Membangun Gallery Embeddings:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache gallery embeddings disimpan.\n",
      "Gallery embeddings siap dengan 55 sampel.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 3: LATIH CLASSIFIER & PERSIAPAN GALERI =============\n",
    "\n",
    "# --- Selalu Latih Classifier dari Galeri ---\n",
    "print(\"Mempersiapkan data latih dari galeri...\")\n",
    "X_train = []\n",
    "y_train_labels = []\n",
    "gallery_files = glob.glob(os.path.join(GALLERY_PATH, '*.jpg')) # Sesuaikan ekstensi\n",
    "\n",
    "if not gallery_files:\n",
    "     print(f\"ERROR: Tidak ada file ditemukan di {GALLERY_PATH}. Pelatihan dibatalkan.\")\n",
    "     sys.exit()\n",
    "\n",
    "for g_file in tqdm(gallery_files, desc=\"Membangun Dataset Latih\"):\n",
    "    subject_id = os.path.basename(g_file).split('_')[0]\n",
    "    embedding = get_embedding(g_file) # Gunakan fungsi get_embedding\n",
    "    if embedding is not None:\n",
    "        X_train.append(embedding)\n",
    "        y_train_labels.append(subject_id)\n",
    "\n",
    "if not X_train:\n",
    "     print(\"ERROR: Tidak ada embedding yang berhasil diekstrak dari galeri. Pelatihan dibatalkan.\")\n",
    "     sys.exit()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_labels)\n",
    "labels = le.classes_\n",
    "print(f\"\\nDataset latih siap dengan {len(X_train)} sampel.\")\n",
    "print(f\"Subjek yang ditemukan: {labels}\")\n",
    "\n",
    "# Latih KNN\n",
    "print(\"\\nMelatih model K-Nearest Neighbors (KNN)...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=12, weights='distance', metric='euclidean')\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"Model KNN selesai dilatih.\")\n",
    "\n",
    "# Latih SVM\n",
    "print(\"Melatih model Support Vector Machine (SVM)...\")\n",
    "svm_model = SVC(kernel='linear', probability=True, C=10.0)\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(\"Model SVM selesai dilatih.\")\n",
    "\n",
    "# >>>>> PERUBAHAN PATH PENYIMPANAN <<<<<\n",
    "knn_model_path_new = os.path.join(NEW_MODELS_PATH, 'knn_model_tuned.pkl')\n",
    "svm_model_path_new = os.path.join(NEW_MODELS_PATH, 'svm_model_tuned.pkl')\n",
    "le_path_new = os.path.join(NEW_MODELS_PATH, 'label_encoder.pkl')\n",
    "\n",
    "with open(knn_model_path_new, 'wb') as f: pickle.dump(knn_model, f)\n",
    "with open(svm_model_path_new, 'wb') as f: pickle.dump(svm_model, f)\n",
    "with open(le_path_new, 'wb') as f: pickle.dump(le, f)\n",
    "print(f\"Model KNN, SVM, dan LabelEncoder baru berhasil disimpan di: {NEW_MODELS_PATH}\")\n",
    "\n",
    "\n",
    "# ============== PERSIAPAN GALLERY EMBEDDINGS UNTUK COSINE SIMILARITY =============\n",
    "print(\"\\nMempersiapkan gallery embeddings untuk cosine similarity...\")\n",
    "gallery_embeddings = []\n",
    "gallery_labels = []\n",
    "gallery_files_cosine = glob.glob(os.path.join(GALLERY_PATH, '*.jpg')) # Sesuaikan ekstensi\n",
    "\n",
    "if not gallery_files_cosine:\n",
    "     print(f\"ERROR: Tidak ada file ditemukan di {GALLERY_PATH} untuk cosine similarity.\")\n",
    "     sys.exit()\n",
    "\n",
    "# Coba muat cache embedding galeri jika ada untuk mempercepat\n",
    "gallery_cache_path = os.path.join(CACHE_PATH, 'gallery_embeddings_cache.pkl')\n",
    "try:\n",
    "    with open(gallery_cache_path, 'rb') as f:\n",
    "        gallery_embeddings, gallery_labels = pickle.load(f)\n",
    "    print(f\"Cache gallery embeddings dimuat ({len(gallery_embeddings)} sampel).\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Cache gallery embeddings tidak ditemukan, membuat ulang...\")\n",
    "    for g_file in tqdm(gallery_files_cosine, desc=\"Membangun Gallery Embeddings\"):\n",
    "        subject_id = os.path.basename(g_file).split('_')[0]\n",
    "        embedding = get_embedding(g_file)\n",
    "        if embedding is not None:\n",
    "            gallery_embeddings.append(embedding)\n",
    "            gallery_labels.append(subject_id)\n",
    "    # Simpan ke cache\n",
    "    try:\n",
    "        with open(gallery_cache_path, 'wb') as f:\n",
    "            pickle.dump((gallery_embeddings, gallery_labels), f)\n",
    "        print(\"Cache gallery embeddings disimpan.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal menyimpan cache gallery embeddings: {e}\")\n",
    "\n",
    "if not gallery_embeddings:\n",
    "     print(\"ERROR: Tidak ada embedding galeri yang berhasil dibuat untuk cosine similarity.\")\n",
    "     sys.exit()\n",
    "else:\n",
    "     print(f\"Gallery embeddings siap dengan {len(gallery_embeddings)} sampel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5bf3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Berhasil memuat 1364 fitur probe dari d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\features_v6.4\\probe_features_v6.4.json\n",
      "\n",
      "=== DEBUG: Memeriksa struktur data pertama ===\n",
      "Keys dalam entry pertama: dict_keys(['file', 'ground_truth', 'metadata', 'restoration_succeeded', 'brisque_original', 'niqe_original', 'brisque_restored', 'niqe_restored', 'embedding_original', 'embedding_restored'])\n",
      "\n",
      "Tipe embedding_original: <class 'list'>\n",
      "Panjang embedding_original: 512\n",
      "Sample (5 elemen pertama): [-0.34173381328582764, 0.9413915276527405, -0.27958348393440247, -0.6649001836776733, -0.07732269167900085]\n",
      "\n",
      "Tipe embedding_restored: <class 'list'>\n",
      "Panjang embedding_restored: 512\n",
      "Sample (5 elemen pertama): [-0.020065119490027428, 0.23978009819984436, 0.06619606912136078, 0.04678422212600708, -0.26042601466178894]\n",
      "==================================================\n",
      "\n",
      "Memulai proses rekognisi untuk ORIGINAL dan RESTORED...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d59602c8964b79a0988692d67c6a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Melakukan Rekognisi:   0%|          | 0/1364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "                    STATISTIK EMBEDDING                     \n",
      "============================================================\n",
      "Total data probe               : 1364\n",
      "Restorasi berhasil             : 1364 (100.0%)\n",
      "\n",
      "Embedding ORIGINAL valid       : 1351 (99.0%)\n",
      "Embedding RESTORED valid       : 1364 (100.0%)\n",
      "Kedua embedding valid          : 1351 (99.0%)\n",
      "============================================================\n",
      "\n",
      "Hasil rekognisi berhasil disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.2_recognition\\recognition_results_v6.4.2_comparison.json\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 4 (REVISI LENGKAP): MUAT FITUR PROBE & LAKUKAN REKOGNISI =============\n",
    "# Versi ini menganalisis KEDUA embedding: original dan restored\n",
    "\n",
    "features_file_path = os.path.join(PROBE_FEATURES_PATH, 'probe_features_v6.4.json')\n",
    "try:\n",
    "    with open(features_file_path, 'r', encoding='utf-8') as f:\n",
    "        probe_features = json.load(f)\n",
    "    print(f\"\\nBerhasil memuat {len(probe_features)} fitur probe dari {features_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File fitur probe tidak ditemukan di {features_file_path}.\")\n",
    "    probe_features = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"ERROR: Gagal mem-parsing file JSON fitur probe: {features_file_path}.\")\n",
    "    probe_features = []\n",
    "\n",
    "# >>>>> DEBUG: Memeriksa struktur data pertama <<<<<\n",
    "if probe_features:\n",
    "    print(\"\\n=== DEBUG: Memeriksa struktur data pertama ===\")\n",
    "    first_entry = probe_features[0]\n",
    "    print(f\"Keys dalam entry pertama: {first_entry.keys()}\")\n",
    "    \n",
    "    emb_orig = first_entry.get('embedding_original')\n",
    "    emb_rest = first_entry.get('embedding_restored')\n",
    "    \n",
    "    print(f\"\\nTipe embedding_original: {type(emb_orig)}\")\n",
    "    if emb_orig and isinstance(emb_orig, list):\n",
    "        print(f\"Panjang embedding_original: {len(emb_orig)}\")\n",
    "        print(f\"Sample (5 elemen pertama): {emb_orig[:5]}\")\n",
    "    \n",
    "    print(f\"\\nTipe embedding_restored: {type(emb_rest)}\")\n",
    "    if emb_rest and isinstance(emb_rest, list):\n",
    "        print(f\"Panjang embedding_restored: {len(emb_rest)}\")\n",
    "        print(f\"Sample (5 elemen pertama): {emb_rest[:5]}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "recognition_results = []\n",
    "\n",
    "# Counters untuk statistik\n",
    "stats = {\n",
    "    'total': 0,\n",
    "    'original_valid': 0,\n",
    "    'restored_valid': 0,\n",
    "    'both_valid': 0,\n",
    "    'restoration_succeeded': 0\n",
    "}\n",
    "\n",
    "if not probe_features:\n",
    "    print(\"Tidak ada fitur probe untuk diproses.\")\n",
    "else:\n",
    "    print(\"\\nMemulai proses rekognisi untuk ORIGINAL dan RESTORED...\")\n",
    "    \n",
    "    for idx, feature_entry in enumerate(tqdm(probe_features, desc=\"Melakukan Rekognisi\")):\n",
    "        stats['total'] += 1\n",
    "        \n",
    "        # >>>>> AMBIL KEDUA EMBEDDING <<<<<\n",
    "        probe_embedding_original = feature_entry.get('embedding_original')\n",
    "        probe_embedding_restored = feature_entry.get('embedding_restored')\n",
    "        \n",
    "        ground_truth = feature_entry.get('ground_truth', 'unknown')\n",
    "        filename = feature_entry.get('file', 'unknown')\n",
    "        metadata = feature_entry.get('metadata', {})\n",
    "        restoration_succeeded = feature_entry.get('restoration_succeeded', False)\n",
    "        \n",
    "        if restoration_succeeded:\n",
    "            stats['restoration_succeeded'] += 1\n",
    "        \n",
    "        # >>>>> STRUKTUR RESULT ENTRY DIPERLUAS <<<<<\n",
    "        result_entry = {\n",
    "            'file': filename,\n",
    "            'ground_truth': ground_truth,\n",
    "            'metadata': metadata,\n",
    "            'restoration_succeeded': restoration_succeeded,\n",
    "            \n",
    "            # Info ORIGINAL\n",
    "            'embedding_original_found': False,\n",
    "            'prediction_knn_original': 'unknown',\n",
    "            'is_correct_knn_original': None,\n",
    "            'probability_knn_original': None,\n",
    "            'prediction_svm_original': 'unknown',\n",
    "            'is_correct_svm_original': None,\n",
    "            'probability_svm_original': None,\n",
    "            'prediction_cosine_original': 'unknown',\n",
    "            'is_correct_cosine_original': None,\n",
    "            'similarity_cosine_original': 0.0,\n",
    "            'is_recognized_cosine_original': False,\n",
    "            \n",
    "            # Info RESTORED\n",
    "            'embedding_restored_found': False,\n",
    "            'prediction_knn_restored': 'unknown',\n",
    "            'is_correct_knn_restored': None,\n",
    "            'probability_knn_restored': None,\n",
    "            'prediction_svm_restored': 'unknown',\n",
    "            'is_correct_svm_restored': None,\n",
    "            'probability_svm_restored': None,\n",
    "            'prediction_cosine_restored': 'unknown',\n",
    "            'is_correct_cosine_restored': None,\n",
    "            'similarity_cosine_restored': 0.0,\n",
    "            'is_recognized_cosine_restored': False\n",
    "        }\n",
    "        \n",
    "        # >>>>> FUNGSI HELPER UNTUK PREDIKSI <<<<<\n",
    "        def predict_all_models(embedding, suffix=''):\n",
    "            \"\"\"Helper function untuk prediksi ketiga model\"\"\"\n",
    "            results = {}\n",
    "            \n",
    "            if embedding is None:\n",
    "                return {\n",
    "                    f'embedding{suffix}_found': False,\n",
    "                    f'is_correct_knn{suffix}': False,\n",
    "                    f'is_correct_svm{suffix}': False,\n",
    "                    f'is_correct_cosine{suffix}': False\n",
    "                }\n",
    "            \n",
    "            # Validasi embedding\n",
    "            has_valid = False\n",
    "            if isinstance(embedding, list) and len(embedding) > 0:\n",
    "                has_valid = True\n",
    "            elif isinstance(embedding, np.ndarray) and embedding.size > 0:\n",
    "                has_valid = True\n",
    "            \n",
    "            if not has_valid:\n",
    "                return {\n",
    "                    f'embedding{suffix}_found': False,\n",
    "                    f'is_correct_knn{suffix}': False,\n",
    "                    f'is_correct_svm{suffix}': False,\n",
    "                    f'is_correct_cosine{suffix}': False\n",
    "                }\n",
    "            \n",
    "            results[f'embedding{suffix}_found'] = True\n",
    "            embedding_np = np.array(embedding).reshape(1, -1)\n",
    "            \n",
    "            # Prediksi KNN\n",
    "            try:\n",
    "                knn_pred_encoded = knn_model.predict(embedding_np)[0]\n",
    "                knn_pred_label = le.inverse_transform([knn_pred_encoded])[0]\n",
    "                knn_proba = knn_model.predict_proba(embedding_np)[0]\n",
    "                results.update({\n",
    "                    f'prediction_knn{suffix}': knn_pred_label,\n",
    "                    f'is_correct_knn{suffix}': knn_pred_label == ground_truth,\n",
    "                    f'probability_knn{suffix}': float(np.max(knn_proba))\n",
    "                })\n",
    "            except Exception as e:\n",
    "                if idx < 5:  # Debug untuk 5 pertama\n",
    "                    print(f\"\\nError KNN{suffix} untuk {filename}: {e}\")\n",
    "                results.update({f'is_correct_knn{suffix}': False})\n",
    "            \n",
    "            # Prediksi SVM\n",
    "            try:\n",
    "                svm_pred_encoded = svm_model.predict(embedding_np)[0]\n",
    "                svm_pred_label = le.inverse_transform([svm_pred_encoded])[0]\n",
    "                svm_proba = svm_model.predict_proba(embedding_np)[0]\n",
    "                results.update({\n",
    "                    f'prediction_svm{suffix}': svm_pred_label,\n",
    "                    f'is_correct_svm{suffix}': svm_pred_label == ground_truth,\n",
    "                    f'probability_svm{suffix}': float(np.max(svm_proba))\n",
    "                })\n",
    "            except Exception as e:\n",
    "                if idx < 5:\n",
    "                    print(f\"\\nError SVM{suffix} untuk {filename}: {e}\")\n",
    "                results.update({f'is_correct_svm{suffix}': False})\n",
    "            \n",
    "            # Prediksi Cosine Similarity\n",
    "            try:\n",
    "                cosine_pred_label, cosine_sim, cosine_rec = cosine_similarity_prediction(\n",
    "                    embedding, gallery_embeddings, gallery_labels\n",
    "                )\n",
    "                results.update({\n",
    "                    f'prediction_cosine{suffix}': cosine_pred_label,\n",
    "                    f'is_correct_cosine{suffix}': cosine_pred_label == ground_truth,\n",
    "                    f'similarity_cosine{suffix}': cosine_sim,\n",
    "                    f'is_recognized_cosine{suffix}': cosine_rec\n",
    "                })\n",
    "            except Exception as e:\n",
    "                if idx < 5:\n",
    "                    print(f\"\\nError Cosine{suffix} untuk {filename}: {e}\")\n",
    "                results.update({f'is_correct_cosine{suffix}': False})\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        # >>>>> PREDIKSI UNTUK ORIGINAL <<<<<\n",
    "        original_results = predict_all_models(probe_embedding_original, '_original')\n",
    "        result_entry.update(original_results)\n",
    "        if original_results.get('embedding_original_found'):\n",
    "            stats['original_valid'] += 1\n",
    "        \n",
    "        # >>>>> PREDIKSI UNTUK RESTORED <<<<<\n",
    "        restored_results = predict_all_models(probe_embedding_restored, '_restored')\n",
    "        result_entry.update(restored_results)\n",
    "        if restored_results.get('embedding_restored_found'):\n",
    "            stats['restored_valid'] += 1\n",
    "        \n",
    "        # Hitung both valid\n",
    "        if original_results.get('embedding_original_found') and restored_results.get('embedding_restored_found'):\n",
    "            stats['both_valid'] += 1\n",
    "        \n",
    "        recognition_results.append(result_entry)\n",
    "    \n",
    "    # >>>>> TAMPILKAN STATISTIK <<<<<\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"STATISTIK EMBEDDING\".center(60))\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total data probe               : {stats['total']}\")\n",
    "    print(f\"Restorasi berhasil             : {stats['restoration_succeeded']} ({stats['restoration_succeeded']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"\\nEmbedding ORIGINAL valid       : {stats['original_valid']} ({stats['original_valid']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"Embedding RESTORED valid       : {stats['restored_valid']} ({stats['restored_valid']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"Kedua embedding valid          : {stats['both_valid']} ({stats['both_valid']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # --- Simpan Hasil Rekognisi ---\n",
    "    results_file_path = os.path.join(RESULTS_PATH, 'recognition_results_v6.4.2_comparison.json')\n",
    "    try:\n",
    "        with open(results_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(recognition_results, f, indent=4, cls=NumpyJSONEncoder)\n",
    "        print(f\"Hasil rekognisi berhasil disimpan ke: {results_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saat menyimpan hasil rekognisi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e0073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "               MEMULAI ANALISIS PERBANDINGAN ORIGINAL VS RESTORED               \n",
      "================================================================================\n",
      "\n",
      "Data dengan embedding ORIGINAL valid: 1351\n",
      "Data dengan embedding RESTORED valid: 1364\n",
      "\n",
      "================================================================================\n",
      "               BAGIAN 1: CLASSIFICATION REPORT & CONFUSION MATRIX               \n",
      "================================================================================\n",
      "\n",
      ">>> EMBEDDING ORIGINAL <<<\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                            KNN - Original Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.90      0.48      0.63       124\n",
      "           b       0.74      0.28      0.41       124\n",
      "           c       1.00      0.26      0.42       122\n",
      "           d       0.97      0.51      0.67       124\n",
      "           e       0.97      0.46      0.63       123\n",
      "           f       0.15      1.00      0.26       120\n",
      "           g       0.95      0.31      0.46       124\n",
      "           h       0.84      0.42      0.56       123\n",
      "           i       1.00      0.35      0.52       121\n",
      "           j       1.00      0.43      0.60       124\n",
      "           k       0.92      0.73      0.81       122\n",
      "\n",
      "    accuracy                           0.47      1351\n",
      "   macro avg       0.86      0.48      0.54      1351\n",
      "weighted avg       0.86      0.47      0.54      1351\n",
      "\n",
      "Confusion matrix disimpan ke: knn_-_original_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                            SVM - Original Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.18      1.00      0.31       124\n",
      "           b       0.94      0.37      0.53       124\n",
      "           c       1.00      0.30      0.47       122\n",
      "           d       1.00      0.47      0.64       124\n",
      "           e       1.00      0.41      0.58       123\n",
      "           f       0.54      0.39      0.45       120\n",
      "           g       0.51      0.58      0.54       124\n",
      "           h       0.77      0.38      0.51       123\n",
      "           i       1.00      0.34      0.51       121\n",
      "           j       1.00      0.55      0.71       124\n",
      "           k       1.00      0.62      0.77       122\n",
      "\n",
      "    accuracy                           0.49      1351\n",
      "   macro avg       0.81      0.49      0.55      1351\n",
      "weighted avg       0.81      0.49      0.55      1351\n",
      "\n",
      "Confusion matrix disimpan ke: svm_-_original_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                     Cosine Similarity - Original Embedding                     \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.19      1.00      0.32       124\n",
      "           b       0.92      0.49      0.64       124\n",
      "           c       0.92      0.39      0.54       122\n",
      "           d       1.00      0.55      0.71       124\n",
      "           e       0.98      0.44      0.61       123\n",
      "           f       0.93      0.33      0.48       120\n",
      "           g       0.58      0.63      0.60       124\n",
      "           h       0.86      0.41      0.55       123\n",
      "           i       1.00      0.45      0.62       121\n",
      "           j       0.92      0.69      0.79       124\n",
      "           k       1.00      0.69      0.82       122\n",
      "\n",
      "    accuracy                           0.55      1351\n",
      "   macro avg       0.85      0.55      0.61      1351\n",
      "weighted avg       0.85      0.55      0.61      1351\n",
      "\n",
      "Confusion matrix disimpan ke: cosine_similarity_-_original_embedding.png\n",
      "================================================================================\n",
      "\n",
      ">>> EMBEDDING RESTORED <<<\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                            KNN - Restored Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.99      0.75      0.85       124\n",
      "           b       0.85      0.48      0.62       124\n",
      "           c       1.00      0.16      0.28       124\n",
      "           d       0.81      0.78      0.80       124\n",
      "           e       0.84      0.63      0.72       124\n",
      "           f       0.22      0.99      0.36       124\n",
      "           g       0.81      0.50      0.62       124\n",
      "           h       0.53      0.42      0.47       124\n",
      "           i       0.82      0.40      0.53       124\n",
      "           j       1.00      0.50      0.67       124\n",
      "           k       0.83      0.80      0.81       124\n",
      "\n",
      "    accuracy                           0.58      1364\n",
      "   macro avg       0.79      0.58      0.61      1364\n",
      "weighted avg       0.79      0.58      0.61      1364\n",
      "\n",
      "Confusion matrix disimpan ke: knn_-_restored_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                            SVM - Restored Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.43      0.93      0.59       124\n",
      "           b       0.76      0.53      0.63       124\n",
      "           c       0.97      0.25      0.40       124\n",
      "           d       0.95      0.73      0.83       124\n",
      "           e       0.95      0.51      0.66       124\n",
      "           f       0.35      0.81      0.49       124\n",
      "           g       0.51      0.81      0.62       124\n",
      "           h       0.65      0.46      0.54       124\n",
      "           i       0.93      0.40      0.56       124\n",
      "           j       0.93      0.71      0.80       124\n",
      "           k       0.95      0.77      0.85       124\n",
      "\n",
      "    accuracy                           0.63      1364\n",
      "   macro avg       0.76      0.63      0.63      1364\n",
      "weighted avg       0.76      0.63      0.63      1364\n",
      "\n",
      "Confusion matrix disimpan ke: svm_-_restored_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                     Cosine Similarity - Restored Embedding                     \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.37      0.90      0.53       124\n",
      "           b       0.73      0.67      0.70       124\n",
      "           c       0.73      0.52      0.61       124\n",
      "           d       0.84      0.79      0.81       124\n",
      "           e       0.88      0.55      0.68       124\n",
      "           f       0.56      0.57      0.57       124\n",
      "           g       0.65      0.73      0.68       124\n",
      "           h       0.77      0.45      0.57       124\n",
      "           i       0.83      0.52      0.64       124\n",
      "           j       0.74      0.79      0.76       124\n",
      "           k       0.82      0.79      0.81       124\n",
      "\n",
      "    accuracy                           0.66      1364\n",
      "   macro avg       0.72      0.66      0.67      1364\n",
      "weighted avg       0.72      0.66      0.67      1364\n",
      "\n",
      "Confusion matrix disimpan ke: cosine_similarity_-_restored_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "           BAGIAN 2: TABEL PERBANDINGAN KINERJA BERDASARKAN SKENARIO            \n",
      "================================================================================\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "                                 Tabel Perbandingan Kinerja - K-Nearest Neighbors (KNN)                                 \n",
      "========================================================================================================================\n",
      "              Skenario           Metode Akurasi (Top-1) Recall F1-Score Peningkatan\n",
      "    Jarak Dekat (< 7m)  Tanpa Restorasi          83.64%   0.84     0.86        None\n",
      "    Jarak Dekat (< 7m) Dengan Restorasi          74.32%   0.74     0.78      -11.1%\n",
      "Jarak Menengah (7-12m)  Tanpa Restorasi          49.43%   0.49     0.54        None\n",
      "Jarak Menengah (7-12m) Dengan Restorasi          68.41%   0.68     0.69      +38.4%\n",
      "   Jarak Jauh (>= 12m)  Tanpa Restorasi          12.76%   0.13     0.07        None\n",
      "   Jarak Jauh (>= 12m) Dengan Restorasi          34.50%   0.35     0.34     +170.4%\n",
      "       Ketinggian 1.5m  Tanpa Restorasi          57.06%   0.57     0.63        None\n",
      "       Ketinggian 1.5m Dengan Restorasi          62.46%   0.62     0.66       +9.5%\n",
      "         Ketinggian 3m  Tanpa Restorasi          56.34%   0.56     0.63        None\n",
      "         Ketinggian 3m Dengan Restorasi          63.05%   0.63     0.65      +11.9%\n",
      "         Ketinggian 4m  Tanpa Restorasi          47.94%   0.48     0.55        None\n",
      "         Ketinggian 4m Dengan Restorasi          63.34%   0.63     0.65      +32.1%\n",
      "         Ketinggian 5m  Tanpa Restorasi          28.01%   0.29     0.30        None\n",
      "         Ketinggian 5m Dengan Restorasi          44.28%   0.44     0.44      +58.1%\n",
      "        Semua Data Uji  Tanpa Restorasi          47.45%   0.48     0.54        None\n",
      "        Semua Data Uji Dengan Restorasi          58.28%   0.58     0.61      +22.8%\n",
      "========================================================================================================================\n",
      "\n",
      "Tabel K-Nearest Neighbors (KNN) disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.2_recognition\\comparison_table_knn_v6.4.2.csv\n",
      "\n",
      "========================================================================================================================\n",
      "                               Tabel Perbandingan Kinerja - Support Vector Machine (SVM)                                \n",
      "========================================================================================================================\n",
      "              Skenario           Metode Akurasi (Top-1) Recall F1-Score Peningkatan\n",
      "    Jarak Dekat (< 7m)  Tanpa Restorasi          85.48%   0.85     0.86        None\n",
      "    Jarak Dekat (< 7m) Dengan Restorasi          77.27%   0.77     0.80       -9.6%\n",
      "Jarak Menengah (7-12m)  Tanpa Restorasi          55.58%   0.56     0.58        None\n",
      "Jarak Menengah (7-12m) Dengan Restorasi          73.64%   0.74     0.73      +32.5%\n",
      "   Jarak Jauh (>= 12m)  Tanpa Restorasi          10.67%   0.11     0.04        None\n",
      "   Jarak Jauh (>= 12m) Dengan Restorasi          39.88%   0.40     0.38     +273.7%\n",
      "       Ketinggian 1.5m  Tanpa Restorasi          58.24%   0.58     0.64        None\n",
      "       Ketinggian 1.5m Dengan Restorasi          65.69%   0.66     0.66      +12.8%\n",
      "         Ketinggian 3m  Tanpa Restorasi          57.82%   0.58     0.63        None\n",
      "         Ketinggian 3m Dengan Restorasi          71.26%   0.71     0.71      +23.3%\n",
      "         Ketinggian 4m  Tanpa Restorasi          51.47%   0.52     0.57        None\n",
      "         Ketinggian 4m Dengan Restorasi          67.16%   0.67     0.67      +30.5%\n",
      "         Ketinggian 5m  Tanpa Restorasi          29.22%   0.29     0.30        None\n",
      "         Ketinggian 5m Dengan Restorasi          47.21%   0.47     0.46      +61.6%\n",
      "        Semua Data Uji  Tanpa Restorasi          49.30%   0.49     0.55        None\n",
      "        Semua Data Uji Dengan Restorasi          62.83%   0.63     0.63      +27.5%\n",
      "========================================================================================================================\n",
      "\n",
      "Tabel Support Vector Machine (SVM) disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.2_recognition\\comparison_table_svm_v6.4.2.csv\n",
      "\n",
      "========================================================================================================================\n",
      "                                     Tabel Perbandingan Kinerja - Cosine Similarity                                     \n",
      "========================================================================================================================\n",
      "              Skenario           Metode Akurasi (Top-1) Recall F1-Score Peningkatan\n",
      "    Jarak Dekat (< 7m)  Tanpa Restorasi          89.40%   0.89     0.90        None\n",
      "    Jarak Dekat (< 7m) Dengan Restorasi          78.64%   0.79     0.81      -12.0%\n",
      "Jarak Menengah (7-12m)  Tanpa Restorasi          65.15%   0.65     0.68        None\n",
      "Jarak Menengah (7-12m) Dengan Restorasi          76.59%   0.77     0.77      +17.6%\n",
      "   Jarak Jauh (>= 12m)  Tanpa Restorasi          15.06%   0.15     0.11        None\n",
      "   Jarak Jauh (>= 12m) Dengan Restorasi          45.66%   0.46     0.45     +203.1%\n",
      "       Ketinggian 1.5m  Tanpa Restorasi          62.35%   0.62     0.68        None\n",
      "       Ketinggian 1.5m Dengan Restorasi          69.21%   0.69     0.70      +11.0%\n",
      "         Ketinggian 3m  Tanpa Restorasi          63.72%   0.64     0.68        None\n",
      "         Ketinggian 3m Dengan Restorasi          77.13%   0.77     0.77      +21.0%\n",
      "         Ketinggian 4m  Tanpa Restorasi          54.71%   0.55     0.60        None\n",
      "         Ketinggian 4m Dengan Restorasi          72.14%   0.72     0.72      +31.9%\n",
      "         Ketinggian 5m  Tanpa Restorasi          39.76%   0.39     0.42        None\n",
      "         Ketinggian 5m Dengan Restorasi          46.63%   0.47     0.46      +17.3%\n",
      "        Semua Data Uji  Tanpa Restorasi          55.22%   0.55     0.61        None\n",
      "        Semua Data Uji Dengan Restorasi          66.28%   0.66     0.67      +20.0%\n",
      "========================================================================================================================\n",
      "\n",
      "Tabel Cosine Similarity disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.2_recognition\\comparison_table_cosine_v6.4.2.csv\n",
      "\n",
      "================================================================================\n",
      "                     BAGIAN 3: SUMMARY PENINGKATAN KINERJA                      \n",
      "================================================================================\n",
      "\n",
      "                       Model Akurasi Original Akurasi Restored Peningkatan\n",
      "   K-Nearest Neighbors (KNN)           47.45%           58.28%      +22.8%\n",
      "Support Vector Machine (SVM)           49.30%           62.83%      +27.5%\n",
      "           Cosine Similarity           55.22%           66.28%      +20.0%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Summary peningkatan disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.2_recognition\\summary_improvement_v6.4.2.csv\n",
      "\n",
      "================================================================================\n",
      "                                ANALISIS SELESAI                                \n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 5: ANALISIS HASIL REKOGNISI (ORIGINAL VS RESTORED) =============\n",
    "\n",
    "if not recognition_results:\n",
    "    print(\"\\nTidak ada hasil rekognisi untuk dianalisis.\")\n",
    "else:\n",
    "    df_results = pd.DataFrame(recognition_results)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MEMULAI ANALISIS PERBANDINGAN ORIGINAL VS RESTORED\".center(80))\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # >>>>> ANALISIS UNTUK ORIGINAL <<<<<\n",
    "    df_original = df_results[df_results['embedding_original_found'] == True].copy()\n",
    "    \n",
    "    # >>>>> ANALISIS UNTUK RESTORED <<<<<\n",
    "    df_restored = df_results[df_results['embedding_restored_found'] == True].copy()\n",
    "    \n",
    "    if df_original.empty and df_restored.empty:\n",
    "        print(\"Tidak ada hasil rekognisi yang memiliki embedding untuk dianalisis.\")\n",
    "    else:\n",
    "        # Prepare metadata columns untuk kedua dataframe\n",
    "        for df in [df_original, df_restored]:\n",
    "            if not df.empty:\n",
    "                df['distance_m'] = df['metadata'].apply(lambda x: x.get('distance_m') if isinstance(x, dict) else None)\n",
    "                df['height_m'] = df['metadata'].apply(lambda x: x.get('height_m') if isinstance(x, dict) else None)\n",
    "        \n",
    "        print(f\"Data dengan embedding ORIGINAL valid: {len(df_original)}\")\n",
    "        print(f\"Data dengan embedding RESTORED valid: {len(df_restored)}\")\n",
    "        \n",
    "        # >>>>> FUNGSI HELPER UNTUK ANALISIS <<<<<\n",
    "        def print_classification_report(title, y_true, y_pred, labels_list, save_cm=True):\n",
    "            \"\"\"Cetak classification report dan confusion matrix\"\"\"\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"{title}\".center(80))\n",
    "            print(f\"{'='*80}\")\n",
    "            print(classification_report(y_true, y_pred, labels=labels_list, zero_division=0))\n",
    "            \n",
    "            if save_cm:\n",
    "                try:\n",
    "                    cm = confusion_matrix(y_true, y_pred, labels=labels_list)\n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    sns.heatmap(cm, annot=True, fmt='d', cmap='viridis',\n",
    "                                xticklabels=labels_list, yticklabels=labels_list)\n",
    "                    plt.title(title)\n",
    "                    plt.ylabel('Label Sebenarnya (Ground Truth)')\n",
    "                    plt.xlabel('Label Prediksi')\n",
    "                    plot_filename = f\"{title.replace(' ', '_').replace('(', '').replace(')', '').lower()}.png\"\n",
    "                    plot_path = os.path.join(RESULTS_PATH, plot_filename)\n",
    "                    plt.savefig(plot_path, dpi=100, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(f\"Confusion matrix disimpan ke: {plot_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Gagal membuat confusion matrix: {e}\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        def calculate_metrics(df, suffix, labels_list):\n",
    "            \"\"\"Hitung metrik untuk satu set data\"\"\"\n",
    "            metrics = {}\n",
    "            for model in ['knn', 'svm', 'cosine']:\n",
    "                is_correct_col = f'is_correct_{model}{suffix}'\n",
    "                prediction_col = f'prediction_{model}{suffix}'\n",
    "                \n",
    "                if is_correct_col in df.columns:\n",
    "                    y_true = df['ground_truth']\n",
    "                    y_pred = df[prediction_col]\n",
    "                    \n",
    "                    accuracy = df[is_correct_col].mean()\n",
    "                    recall = recall_score(y_true, y_pred, average='macro', zero_division=0, labels=labels_list)\n",
    "                    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0, labels=labels_list)\n",
    "                    \n",
    "                    metrics[model] = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1\n",
    "                    }\n",
    "            return metrics\n",
    "        \n",
    "        # >>>>> ANALISIS OVERALL (CONFUSION MATRIX & REPORT) <<<<<\n",
    "        \n",
    "        # Get labels yang ada di data\n",
    "        labels_original = sorted(df_original['ground_truth'].unique()) if not df_original.empty else []\n",
    "        labels_restored = sorted(df_restored['ground_truth'].unique()) if not df_restored.empty else []\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"BAGIAN 1: CLASSIFICATION REPORT & CONFUSION MATRIX\".center(80))\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # --- ORIGINAL ---\n",
    "        if not df_original.empty:\n",
    "            print(\"\\n>>> EMBEDDING ORIGINAL <<<\\n\")\n",
    "            print_classification_report(\n",
    "                \"KNN - Original Embedding\",\n",
    "                df_original['ground_truth'],\n",
    "                df_original['prediction_knn_original'],\n",
    "                labels_original\n",
    "            )\n",
    "            print_classification_report(\n",
    "                \"SVM - Original Embedding\",\n",
    "                df_original['ground_truth'],\n",
    "                df_original['prediction_svm_original'],\n",
    "                labels_original\n",
    "            )\n",
    "            print_classification_report(\n",
    "                \"Cosine Similarity - Original Embedding\",\n",
    "                df_original['ground_truth'],\n",
    "                df_original['prediction_cosine_original'],\n",
    "                labels_original\n",
    "            )\n",
    "        \n",
    "        # --- RESTORED ---\n",
    "        if not df_restored.empty:\n",
    "            print(\"\\n>>> EMBEDDING RESTORED <<<\\n\")\n",
    "            print_classification_report(\n",
    "                \"KNN - Restored Embedding\",\n",
    "                df_restored['ground_truth'],\n",
    "                df_restored['prediction_knn_restored'],\n",
    "                labels_restored\n",
    "            )\n",
    "            print_classification_report(\n",
    "                \"SVM - Restored Embedding\",\n",
    "                df_restored['ground_truth'],\n",
    "                df_restored['prediction_svm_restored'],\n",
    "                labels_restored\n",
    "            )\n",
    "            print_classification_report(\n",
    "                \"Cosine Similarity - Restored Embedding\",\n",
    "                df_restored['ground_truth'],\n",
    "                df_restored['prediction_cosine_restored'],\n",
    "                labels_restored\n",
    "            )\n",
    "        \n",
    "        # >>>>> BAGIAN 2: TABEL PERBANDINGAN BERDASARKAN SKENARIO <<<<<\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"BAGIAN 2: TABEL PERBANDINGAN KINERJA BERDASARKAN SKENARIO\".center(80))\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Define scenarios\n",
    "        scenarios = [\n",
    "            {\"name\": \"Jarak Dekat (< 7m)\", \"filter_key\": \"distance_m\", \"condition\": lambda x: x < 7},\n",
    "            {\"name\": \"Jarak Menengah (7-12m)\", \"filter_key\": \"distance_m\", \"condition\": lambda x: 7 <= x < 12},\n",
    "            {\"name\": \"Jarak Jauh (>= 12m)\", \"filter_key\": \"distance_m\", \"condition\": lambda x: x >= 12},\n",
    "            {\"name\": \"Ketinggian 1.5m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 1.5},\n",
    "            {\"name\": \"Ketinggian 3m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 3},\n",
    "            {\"name\": \"Ketinggian 4m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 4},\n",
    "            {\"name\": \"Ketinggian 5m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 5},\n",
    "            {\"name\": \"Semua Data Uji\", \"filter_key\": None, \"condition\": None}\n",
    "        ]\n",
    "        \n",
    "        # Create separate tables for each model\n",
    "        models = ['knn', 'svm', 'cosine']\n",
    "        model_names = {\n",
    "            'knn': 'K-Nearest Neighbors (KNN)',\n",
    "            'svm': 'Support Vector Machine (SVM)',\n",
    "            'cosine': 'Cosine Similarity'\n",
    "        }\n",
    "        \n",
    "        all_tables = {}\n",
    "        \n",
    "        for model in models:\n",
    "            comparison_data = []\n",
    "            \n",
    "            for scenario in scenarios:\n",
    "                scenario_name = scenario[\"name\"]\n",
    "                \n",
    "                # Filter data untuk scenario\n",
    "                if scenario[\"filter_key\"] is None:\n",
    "                    # Semua data\n",
    "                    filtered_orig = df_original\n",
    "                    filtered_rest = df_restored\n",
    "                else:\n",
    "                    filter_key = scenario[\"filter_key\"]\n",
    "                    condition = scenario[\"condition\"]\n",
    "                    filtered_orig = df_original[\n",
    "                        df_original[filter_key].notna() & \n",
    "                        df_original[filter_key].apply(condition)\n",
    "                    ] if not df_original.empty else pd.DataFrame()\n",
    "                    filtered_rest = df_restored[\n",
    "                        df_restored[filter_key].notna() & \n",
    "                        df_restored[filter_key].apply(condition)\n",
    "                    ] if not df_restored.empty else pd.DataFrame()\n",
    "                \n",
    "                # Calculate metrics untuk ORIGINAL\n",
    "                if not filtered_orig.empty:\n",
    "                    labels_scenario = sorted(filtered_orig['ground_truth'].unique())\n",
    "                    metrics_orig = calculate_metrics(filtered_orig, '_original', labels_scenario)\n",
    "                    \n",
    "                    if model in metrics_orig:\n",
    "                        acc_orig = metrics_orig[model]['accuracy']\n",
    "                        rec_orig = metrics_orig[model]['recall']\n",
    "                        f1_orig = metrics_orig[model]['f1']\n",
    "                        comparison_data.append([\n",
    "                            scenario_name,\n",
    "                            'Tanpa Restorasi',\n",
    "                            f'{acc_orig:.2%}',\n",
    "                            f'{rec_orig:.2f}',\n",
    "                            f'{f1_orig:.2f}'\n",
    "                        ])\n",
    "                else:\n",
    "                    comparison_data.append([\n",
    "                        scenario_name,\n",
    "                        'Tanpa Restorasi',\n",
    "                        'N/A',\n",
    "                        'N/A',\n",
    "                        'N/A'\n",
    "                    ])\n",
    "                \n",
    "                # Calculate metrics untuk RESTORED\n",
    "                if not filtered_rest.empty:\n",
    "                    labels_scenario = sorted(filtered_rest['ground_truth'].unique())\n",
    "                    metrics_rest = calculate_metrics(filtered_rest, '_restored', labels_scenario)\n",
    "                    \n",
    "                    if model in metrics_rest:\n",
    "                        acc_rest = metrics_rest[model]['accuracy']\n",
    "                        rec_rest = metrics_rest[model]['recall']\n",
    "                        f1_rest = metrics_rest[model]['f1']\n",
    "                        \n",
    "                        # Calculate improvement\n",
    "                        if not filtered_orig.empty and model in metrics_orig:\n",
    "                            acc_orig = metrics_orig[model]['accuracy']\n",
    "                            improvement = ((acc_rest - acc_orig) / acc_orig * 100) if acc_orig > 0 else 0\n",
    "                            improvement_str = f'{improvement:+.1f}%'\n",
    "                        else:\n",
    "                            improvement_str = 'N/A'\n",
    "                        \n",
    "                        comparison_data.append([\n",
    "                            scenario_name,\n",
    "                            'Dengan Restorasi',\n",
    "                            f'{acc_rest:.2%}',\n",
    "                            f'{rec_rest:.2f}',\n",
    "                            f'{f1_rest:.2f}',\n",
    "                            improvement_str\n",
    "                        ])\n",
    "                else:\n",
    "                    comparison_data.append([\n",
    "                        scenario_name,\n",
    "                        'Dengan Restorasi',\n",
    "                        'N/A',\n",
    "                        'N/A',\n",
    "                        'N/A',\n",
    "                        'N/A'\n",
    "                    ])\n",
    "            \n",
    "            all_tables[model] = comparison_data\n",
    "        \n",
    "        # >>>>> TAMPILKAN TABEL <<<<<\n",
    "        columns = ['Skenario', 'Metode', 'Akurasi (Top-1)', 'Recall', 'F1-Score', 'Peningkatan']\n",
    "        \n",
    "        for model in models:\n",
    "            if all_tables[model]:\n",
    "                table_df = pd.DataFrame(all_tables[model], columns=columns)\n",
    "                print(f\"\\n{'='*120}\")\n",
    "                print(f\"Tabel Perbandingan Kinerja - {model_names[model]}\".center(120))\n",
    "                print(f\"{'='*120}\")\n",
    "                print(table_df.to_string(index=False))\n",
    "                print(f\"{'='*120}\\n\")\n",
    "                \n",
    "                # Save to CSV\n",
    "                try:\n",
    "                    csv_path = os.path.join(RESULTS_PATH, f'comparison_table_{model}_v6.4.2.csv')\n",
    "                    table_df.to_csv(csv_path, index=False)\n",
    "                    print(f\"Tabel {model_names[model]} disimpan ke: {csv_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Gagal menyimpan tabel {model}: {e}\")\n",
    "        \n",
    "        # >>>>> BAGIAN 3: SUMMARY STATISTIK <<<<<\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"BAGIAN 3: SUMMARY PENINGKATAN KINERJA\".center(80))\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Calculate overall improvement\n",
    "        if not df_original.empty and not df_restored.empty:\n",
    "            # Get common ground truth labels\n",
    "            common_labels = sorted(set(df_original['ground_truth'].unique()) & \n",
    "                                 set(df_restored['ground_truth'].unique()))\n",
    "            \n",
    "            if common_labels:\n",
    "                overall_orig = calculate_metrics(df_original, '_original', common_labels)\n",
    "                overall_rest = calculate_metrics(df_restored, '_restored', common_labels)\n",
    "                \n",
    "                summary_data = []\n",
    "                for model in models:\n",
    "                    if model in overall_orig and model in overall_rest:\n",
    "                        acc_orig = overall_orig[model]['accuracy']\n",
    "                        acc_rest = overall_rest[model]['accuracy']\n",
    "                        improvement = ((acc_rest - acc_orig) / acc_orig * 100) if acc_orig > 0 else 0\n",
    "                        \n",
    "                        summary_data.append([\n",
    "                            model_names[model],\n",
    "                            f'{acc_orig:.2%}',\n",
    "                            f'{acc_rest:.2%}',\n",
    "                            f'{improvement:+.1f}%'\n",
    "                        ])\n",
    "                \n",
    "                if summary_data:\n",
    "                    summary_df = pd.DataFrame(summary_data, \n",
    "                                            columns=['Model', 'Akurasi Original', 'Akurasi Restored', 'Peningkatan'])\n",
    "                    print(summary_df.to_string(index=False))\n",
    "                    print(f\"\\n{'='*80}\\n\")\n",
    "                    \n",
    "                    # Save summary\n",
    "                    try:\n",
    "                        summary_path = os.path.join(RESULTS_PATH, 'summary_improvement_v6.4.2.csv')\n",
    "                        summary_df.to_csv(summary_path, index=False)\n",
    "                        print(f\"Summary peningkatan disimpan ke: {summary_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Gagal menyimpan summary: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALISIS SELESAI\".center(80))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367660ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
