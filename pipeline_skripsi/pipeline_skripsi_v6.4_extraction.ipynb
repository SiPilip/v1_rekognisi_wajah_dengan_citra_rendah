{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Semua pustaka berhasil diimpor.\n",
      "Direktori telah disiapkan.\n",
      "Menggunakan device: cuda\n",
      "Memuat model GFPGAN v1.4...\n",
      "Model GFPGAN siap.\n",
      "Memuat model NR-IQA...\n",
      "Model BRISQUE & NIQE siap.\n",
      "Warm-up model DeepFace (ArcFace)...\n",
      "Model DeepFace siap.\n"
     ]
    }
   ],
   "source": [
    "##### Impor Pustaka & Konfigurasi Path #####\n",
    "\n",
    "# ============== LANGKAH 1: INISIALISASI & SETUP =============\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "from gfpgan import GFPGANer\n",
    "import pyiqa\n",
    "\n",
    "print(\"Semua pustaka berhasil diimpor.\")\n",
    "\n",
    "# Definisikan kelas Encoder kustom untuk menangani tipe data NumPy\n",
    "class NumpyJSONEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.int_, np.intc, np.intp, np.int8,\n",
    "                            np.int16, np.int32, np.int64, np.uint8,\n",
    "                            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj) # Konversi integer NumPy ke int Python\n",
    "        elif isinstance(obj, (np.floating, np.float_, np.float16,\n",
    "                              np.float32, np.float64)):\n",
    "            return float(obj) # Konversi float NumPy ke float Python\n",
    "        elif isinstance(obj, (np.bool_)):\n",
    "            return bool(obj) # Konversi boolean NumPy ke bool Python\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist() # Konversi array NumPy ke list Python\n",
    "\n",
    "        # Biarkan encoder default menangani tipe data lainnya\n",
    "        return super(NumpyJSONEncoder, self).default(obj)\n",
    "\n",
    "# --- Konfigurasi Path ---\n",
    "BASE_DIR = os.path.abspath('.')\n",
    "# GALLERY_PATH = os.path.join(BASE_DIR, 'data', 'gallery6.2') # Tidak diperlukan di v6.4\n",
    "PROBES_PATH = os.path.join(BASE_DIR, 'data', 'probes')\n",
    "RESULTS_PATH = os.path.join(BASE_DIR, 'results_v6.4_extraction') # Path untuk output gambar\n",
    "CACHE_PATH = os.path.join(BASE_DIR, 'cache_v6.4_extraction') # Path cache jika diperlukan\n",
    "PROBE_FEATURES_PATH = os.path.join(BASE_DIR, 'features_v6.4') # Path untuk menyimpan fitur probe\n",
    "\n",
    "# Pastikan semua direktori ada\n",
    "for path in [RESULTS_PATH, CACHE_PATH, PROBE_FEATURES_PATH]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "print(\"Direktori telah disiapkan.\")\n",
    "\n",
    "# --- Setup Device & Pemuatan Model ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Menggunakan device: {DEVICE}')\n",
    "\n",
    "# Muat GFPGAN\n",
    "print(\"Memuat model GFPGAN v1.4...\")\n",
    "# Sesuaikan path ini jika perlu\n",
    "gfpgan_model_path = r'D:\\\\UNSRI_DATA\\\\_SKRIPSI\\\\PROGRAM\\\\v1\\\\model_gfpgan\\\\gfpgan\\\\weights\\\\GFPGANv1.4.pth'\n",
    "gfpgan_restorer = GFPGANer(model_path=gfpgan_model_path, upscale=2, arch='clean',\n",
    "                           channel_multiplier=2, bg_upsampler=None, device=DEVICE)\n",
    "print(\"Model GFPGAN siap.\")\n",
    "\n",
    "# Muat IQA Assessors\n",
    "print(\"Memuat model NR-IQA...\")\n",
    "brisque_assessor = pyiqa.create_metric('brisque', device=DEVICE)\n",
    "niqe_assessor = pyiqa.create_metric('niqe', device=DEVICE)\n",
    "print(\"Model BRISQUE & NIQE siap.\")\n",
    "\n",
    "# Warm-up DeepFace\n",
    "print(\"Warm-up model DeepFace (ArcFace)...\")\n",
    "_ = DeepFace.represent(np.zeros((112, 112, 3), dtype=np.uint8), model_name='ArcFace', enforce_detection=False)\n",
    "print(\"Model DeepFace siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi-fungsi utilitas siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 2: DEFINISI FUNGSI UTILITAS =============\n",
    "\n",
    "def parse_filename(filename: str) -> dict | None:\n",
    "    \"\"\"Menganalisis nama file probe untuk mendapatkan metadata.\"\"\"\n",
    "    try:\n",
    "        base_name = os.path.basename(filename)\n",
    "        parts = os.path.splitext(base_name)[0].split('_')\n",
    "        # Asumsi format: 'subject_X_height_Y_distance_Z.JPG'\n",
    "        if len(parts) >= 5:\n",
    "             subject_id = parts[0]\n",
    "             height_id = parts[2]\n",
    "             distance_id = parts[4]\n",
    "             # Konversi ID jarak ke meter (sesuaikan logika ini jika perlu)\n",
    "             distance_m = 17 - (int(distance_id) / 2)\n",
    "             # Konversi ID ketinggian ke meter (sesuaikan logika ini jika perlu)\n",
    "             height_m = 1.5 if height_id == \"0\" else int(height_id)\n",
    "             return {'subject_id': subject_id, 'height_m': height_m, 'distance_m': distance_m}\n",
    "        return {'subject_id': parts[0]} # Fallback jika format tidak lengkap\n",
    "    except (IndexError, ValueError):\n",
    "        # Tangani error jika nama file tidak sesuai format atau konversi gagal\n",
    "        try:\n",
    "             # Coba parsing hanya subject_id jika format lengkap gagal\n",
    "             base_name = os.path.basename(filename)\n",
    "             parts = os.path.splitext(base_name)[0].split('_')\n",
    "             return {'subject_id': parts[0]}\n",
    "        except:\n",
    "            print(f\"Peringatan: Gagal mem-parsing nama file: {filename}\")\n",
    "            return None\n",
    "\n",
    "# Fungsi ini mungkin tidak digunakan langsung di loop utama v6.4,\n",
    "# tapi bisa berguna untuk analisis lain atau jika ingin memproses probe non-restorasi\n",
    "def get_embedding(image_path_or_array, model_name='ArcFace', detector_backend='retinaface') -> list | None:\n",
    "    \"\"\"Mengekstrak embedding wajah dari path gambar atau array (dengan deteksi).\"\"\"\n",
    "    try:\n",
    "        embedding_objs = DeepFace.represent(\n",
    "            img_path=image_path_or_array, model_name=model_name,\n",
    "            enforce_detection=True, detector_backend=detector_backend\n",
    "        )\n",
    "        # DeepFace.represent bisa mengembalikan list jika ada >1 wajah, ambil yg pertama\n",
    "        if embedding_objs and isinstance(embedding_objs, list):\n",
    "            return embedding_objs[0]['embedding']\n",
    "        return None # Tidak ada wajah terdeteksi atau format output tidak sesuai\n",
    "    except Exception as e:\n",
    "        # print(f\"Error saat get_embedding: {e}\") # Uncomment untuk debug\n",
    "        return None\n",
    "\n",
    "def get_embedding_from_cropped(cropped_face_array, model_name='ArcFace') -> list | None:\n",
    "    \"\"\"Mengekstrak embedding dari array gambar wajah yang sudah di-crop (tanpa deteksi ulang).\"\"\"\n",
    "    if cropped_face_array is None or cropped_face_array.size == 0:\n",
    "        return None\n",
    "    try:\n",
    "        # Pastikan input adalah BGR numpy array\n",
    "        if not isinstance(cropped_face_array, np.ndarray):\n",
    "             return None\n",
    "\n",
    "        embedding_objs = DeepFace.represent(\n",
    "            img_path=cropped_face_array, model_name=model_name,\n",
    "            enforce_detection=False # Penting: tidak perlu deteksi ulang\n",
    "        )\n",
    "        # Asumsi output selalu list, ambil embedding pertama\n",
    "        if embedding_objs and isinstance(embedding_objs, list):\n",
    "            return embedding_objs[0]['embedding']\n",
    "        return None # Format output tidak sesuai\n",
    "    except Exception as e:\n",
    "        # print(f\"Error saat get_embedding_from_cropped: {e}\") # Uncomment untuk debug\n",
    "        return None\n",
    "\n",
    "def get_nr_iqa_score(image_array, assessor):\n",
    "    \"\"\"Menghitung skor kualitas gambar (BRISQUE/NIQE) dari array gambar.\"\"\"\n",
    "    if image_array is None or image_array.size == 0: return None\n",
    "    try:\n",
    "        # Pastikan input adalah BGR numpy array\n",
    "        if not isinstance(image_array, np.ndarray): return None\n",
    "\n",
    "        # Konversi ke RGB dan tensor PyTorch\n",
    "        img_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "        # Pastikan tipe data tensor adalah float dan normalisasi ke [0, 1]\n",
    "        img_tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        score = assessor(img_tensor.to(DEVICE)).item()\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        # print(f\"Error saat get_nr_iqa_score: {e}\") # Uncomment untuk debug\n",
    "        return None\n",
    "\n",
    "def save_comparison_image(original_img, restored_img, save_path):\n",
    "    \"\"\"Menyimpan gambar perbandingan (probe vs restorasi) secara berdampingan.\"\"\"\n",
    "    if original_img is None or restored_img is None:\n",
    "        return False\n",
    "    try:\n",
    "        target_height = max(original_img.shape[0], restored_img.shape[0])\n",
    "\n",
    "        def resize_keep_aspect(img):\n",
    "            if img.shape[0] == target_height:\n",
    "                return img\n",
    "            scale = target_height / img.shape[0]\n",
    "            new_width = int(img.shape[1] * scale)\n",
    "            return cv2.resize(img, (new_width, target_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        original_resized = resize_keep_aspect(original_img)\n",
    "        restored_resized = resize_keep_aspect(restored_img)\n",
    "        comparison = np.hstack([original_resized, restored_resized])\n",
    "        cv2.imwrite(save_path, comparison)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membuat gambar perbandingan: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"Fungsi-fungsi utilitas siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai pemrosesan 1364 citra probe...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ce962a80e641469dd5d2b0f31f3ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Memproses Probe:   0%|          | 0/1364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peringatan: Gagal ekstrak embedding dari citra asli c_gp_5_ef_28.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli c_gp_5_ef_29.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli e_gp_5_ef_10.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli f_gp_5_ef_27.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli f_gp_5_ef_28.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli f_gp_5_ef_29.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli f_gp_5_ef_30.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli h_gp_5_ef_02.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli i_gp_0_ef_15.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli i_gp_3_ef_00.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli i_gp_3_ef_02.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli k_gp_4_ef_00.jpg\n",
      "Peringatan: Gagal ekstrak embedding dari citra asli k_gp_5_ef_01.jpg\n",
      "\n",
      "Fitur probe berhasil diekstrak dan disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\features_v6.4\\probe_features_v6.4.json\n",
      "Jumlah data fitur yang disimpan: 1364\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 3: PEMROSESAN PROBE & EKSTRAKSI FITUR =============\n",
    "\n",
    "# Buat direktori untuk menyimpan gambar output (jika ingin disimpan terpisah)\n",
    "CROPPED_FACES_PATH = os.path.join(RESULTS_PATH, 'cropped_faces')\n",
    "RESTORED_FACES_PATH = os.path.join(RESULTS_PATH, 'restored_faces')\n",
    "RESTORED_IMGS_PATH = os.path.join(RESULTS_PATH, 'restored_imgs')\n",
    "COMPARISON_PATH = os.path.join(RESULTS_PATH, 'cmp')\n",
    "\n",
    "for path in [CROPPED_FACES_PATH, RESTORED_FACES_PATH, RESTORED_IMGS_PATH, COMPARISON_PATH]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "probe_files = glob.glob(os.path.join(PROBES_PATH, '*.JPG')) # Sesuaikan ekstensi jika perlu\n",
    "probe_features = [] # List untuk menyimpan hasil ekstraksi fitur\n",
    "print(f\"Memulai pemrosesan {len(probe_files)} citra probe...\")\n",
    "\n",
    "for probe_path in tqdm(probe_files, desc=\"Memproses Probe\"):\n",
    "    metadata = parse_filename(probe_path)\n",
    "    # Langkahi file jika gagal parsing nama file\n",
    "    if not metadata or 'subject_id' not in metadata:\n",
    "        print(f\"Peringatan: Melangkahi file karena gagal parsing metadata: {probe_path}\")\n",
    "        continue\n",
    "\n",
    "    probe_filename = os.path.basename(probe_path)\n",
    "    ground_truth_label = metadata.get('subject_id', 'unknown') # Ambil subject_id dengan aman\n",
    "\n",
    "    # Inisialisasi hasil untuk file probe ini\n",
    "    feature_entry = {\n",
    "        'file': probe_filename,\n",
    "        'ground_truth': ground_truth_label,\n",
    "        'metadata': metadata, # Simpan semua metadata yang berhasil diparsing\n",
    "        'restoration_succeeded': False,\n",
    "        'brisque_original': None,\n",
    "        'niqe_original': None,\n",
    "        'brisque_restored': None,\n",
    "        'niqe_restored': None,\n",
    "        'embedding_original': None,\n",
    "        'embedding_restored': None\n",
    "        }\n",
    "\n",
    "    # --- Baca gambar probe ---\n",
    "    try:\n",
    "        # Gunakan imdecode untuk menangani path dengan karakter non-ASCII\n",
    "        img_probe = cv2.imdecode(np.fromfile(probe_path, np.uint8), cv2.IMREAD_COLOR)\n",
    "        if img_probe is None:\n",
    "            print(f\"Peringatan: Gagal membaca gambar probe: {probe_path}\")\n",
    "            probe_features.append(feature_entry) # Simpan entri dengan data kosong\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membaca {probe_path}: {e}\")\n",
    "        probe_features.append(feature_entry)\n",
    "        continue\n",
    "\n",
    "    # --- Hitung IQA Original ---\n",
    "    feature_entry['brisque_original'] = get_nr_iqa_score(img_probe, brisque_assessor)\n",
    "    feature_entry['niqe_original'] = get_nr_iqa_score(img_probe, niqe_assessor)\n",
    "\n",
    "    # --- Ekstrak Embedding dari Citra Asli ---\n",
    "    embedding_original = get_embedding(img_probe, model_name='ArcFace', detector_backend='retinaface')\n",
    "    if embedding_original:\n",
    "        feature_entry['embedding_original'] = embedding_original\n",
    "    else:\n",
    "        print(f\"Peringatan: Gagal ekstrak embedding dari citra asli {probe_filename}\")\n",
    "\n",
    "    # --- Lakukan Restorasi dengan GFPGAN ---\n",
    "    try:\n",
    "        _, restored_faces, restored_pasted_img = gfpgan_restorer.enhance(\n",
    "            img_probe,\n",
    "            has_aligned=True, \n",
    "            only_center_face=False # Ambil semua wajah, proses yg pertama\n",
    "            )\n",
    "\n",
    "        # Cek apakah restorasi berhasil dan menghasilkan wajah\n",
    "        if restored_faces and restored_faces[0] is not None:\n",
    "            restored_face = restored_faces[0] # Ambil wajah pertama yang direstorasi\n",
    "            feature_entry['restoration_succeeded'] = True\n",
    "\n",
    "            # --- Hitung IQA Restored ---\n",
    "            feature_entry['brisque_restored'] = get_nr_iqa_score(restored_face, brisque_assessor)\n",
    "            feature_entry['niqe_restored'] = get_nr_iqa_score(restored_face, niqe_assessor)\n",
    "\n",
    "            # --- Ekstrak Embedding dari Wajah Hasil Restorasi ---\n",
    "            embedding_B = get_embedding_from_cropped(restored_face, model_name='ArcFace')\n",
    "            if embedding_B:\n",
    "                feature_entry['embedding_restored'] = embedding_B\n",
    "            else:\n",
    "                print(f\"Peringatan: Gagal ekstrak embedding dari wajah restorasi {probe_filename}\")\n",
    "\n",
    "            cv2.imwrite(os.path.join(RESTORED_FACES_PATH, probe_filename), restored_face)\n",
    "            cv2.imwrite(os.path.join(CROPPED_FACES_PATH, probe_filename), restored_face)\n",
    "\n",
    "            comparison_source = restored_pasted_img if restored_pasted_img is not None else restored_face\n",
    "            cmp_save_path = os.path.join(COMPARISON_PATH, probe_filename)\n",
    "            if not save_comparison_image(img_probe, comparison_source, cmp_save_path):\n",
    "                print(f\"Peringatan: Gagal menyimpan gambar perbandingan untuk {probe_filename}\")\n",
    "\n",
    "            if restored_pasted_img is not None:\n",
    "                cv2.imwrite(os.path.join(RESTORED_IMGS_PATH, probe_filename), restored_pasted_img)\n",
    "        else:\n",
    "             print(f\"Peringatan: Restorasi GFPGAN tidak menghasilkan wajah untuk {probe_filename}\")\n",
    "\n",
    "    except Exception as enhance_e:\n",
    "        print(f\"Error saat proses enhance/embedding GFPGAN untuk {probe_filename}: {enhance_e}\")\n",
    "\n",
    "    probe_features.append(feature_entry)\n",
    "\n",
    "# --- Simpan Hasil Ekstraksi Fitur ---\n",
    "features_file_path = os.path.join(PROBE_FEATURES_PATH, 'probe_features_v6.4.json')\n",
    "try:\n",
    "    with open(features_file_path, 'w', encoding='utf-8') as f: # Gunakan encoding utf-8\n",
    "        # Gunakan NumpyJSONEncoder untuk menyimpan embedding (list of floats)\n",
    "        json.dump(probe_features, f, indent=4, cls=NumpyJSONEncoder)\n",
    "    print(f\"\\nFitur probe berhasil diekstrak dan disimpan ke: {features_file_path}\")\n",
    "    print(f\"Jumlah data fitur yang disimpan: {len(probe_features)}\")\n",
    "except Exception as save_e:\n",
    "    print(f\"\\nERROR saat menyimpan hasil fitur: {save_e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
