{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d44431c",
   "metadata": {},
   "source": [
    "svm_model = SVC(kernel='rbf', C=10.0, gamma='scale', probability=True)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='manhattan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb451e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Semua pustaka berhasil diimpor.\n",
      "Direktori telah disiapkan.\n",
      "Menggunakan device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 1: INISIALISASI & SETUP =============\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from deepface import DeepFace # Diperlukan untuk get_embedding gallery\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, f1_score, precision_score\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Semua pustaka berhasil diimpor.\")\n",
    "\n",
    "# Definisikan kelas Encoder kustom (jika diperlukan untuk menyimpan hasil baru)\n",
    "class NumpyJSONEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer): return int(obj)\n",
    "        elif isinstance(obj, np.floating): return float(obj)\n",
    "        elif isinstance(obj, np.ndarray): return obj.tolist()\n",
    "        elif isinstance(obj, np.bool_): return bool(obj)\n",
    "        else: return super(NumpyJSONEncoder, self).default(obj)\n",
    "\n",
    "# --- Konfigurasi Path ---\n",
    "BASE_DIR = os.path.abspath('.')\n",
    "GALLERY_PATH = os.path.join(BASE_DIR, 'data', 'gallery6.2') # Path galeri tetap diperlukan\n",
    "RESULTS_PATH = os.path.join(BASE_DIR, 'results_v6.4.3.2_recognition') # Path output analisis\n",
    "CACHE_PATH = os.path.join(BASE_DIR, 'cache_v6.4.3.2_recognition') # Path cache jika diperlukan\n",
    "# >>>>> PERUBAHAN PATH MODEL BARU <<<<<\n",
    "NEW_MODELS_PATH = os.path.join(BASE_DIR, 'models_v6.4.3.2_tuned') # Path BARU untuk menyimpan model hasil tuning\n",
    "PROBE_FEATURES_PATH = os.path.join(BASE_DIR, 'features_v6.4') # Path fitur probe dari v6.4\n",
    "\n",
    "# Pastikan semua direktori ada\n",
    "for path in [RESULTS_PATH, CACHE_PATH, NEW_MODELS_PATH]: # Tambahkan NEW_MODELS_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "print(\"Direktori telah disiapkan.\")\n",
    "\n",
    "# --- Setup Device ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Menggunakan device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea45974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi-fungsi utilitas siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 2: DEFINISI FUNGSI UTILITAS =============\n",
    "\n",
    "# Fungsi get_embedding diperlukan untuk melatih classifier dari galeri\n",
    "def get_embedding(image_path_or_array, model_name='ArcFace', detector_backend='retinaface') -> list | None:\n",
    "    \"\"\"Mengekstrak embedding wajah dari path gambar atau array (dengan deteksi).\"\"\"\n",
    "    try:\n",
    "        embedding_objs = DeepFace.represent(\n",
    "            img_path=image_path_or_array, model_name=model_name,\n",
    "            enforce_detection=True, detector_backend=detector_backend\n",
    "        )\n",
    "        if embedding_objs and isinstance(embedding_objs, list):\n",
    "            return embedding_objs[0]['embedding']\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error saat get_embedding: {e}\") # Uncomment untuk debug\n",
    "        return None\n",
    "\n",
    "# Fungsi Cosine Similarity diperlukan untuk perbandingan\n",
    "def cosine_similarity_prediction(query_embedding, gallery_embeddings, gallery_labels, threshold=0.5):\n",
    "    \"\"\"Prediksi menggunakan cosine similarity.\"\"\"\n",
    "    if query_embedding is None or not gallery_embeddings:\n",
    "        return \"unknown\", 0.0, False\n",
    "\n",
    "    query_embedding = np.array(query_embedding)\n",
    "    query_norm = np.linalg.norm(query_embedding)\n",
    "    if query_norm == 0:\n",
    "        return \"unknown\", 0.0, False\n",
    "    query_embedding = query_embedding / query_norm\n",
    "\n",
    "    similarities = []\n",
    "    valid_gallery_labels = []\n",
    "    for gallery_emb, label in zip(gallery_embeddings, gallery_labels):\n",
    "        gallery_emb = np.array(gallery_emb)\n",
    "        gallery_norm = np.linalg.norm(gallery_emb)\n",
    "        if gallery_norm > 0:\n",
    "            gallery_emb = gallery_emb / gallery_norm\n",
    "            similarity = np.dot(query_embedding, gallery_emb)\n",
    "            similarities.append(similarity)\n",
    "            valid_gallery_labels.append(label)\n",
    "\n",
    "    if not similarities:\n",
    "        return \"unknown\", 0.0, False\n",
    "\n",
    "    max_similarity = np.max(similarities)\n",
    "    max_idx = np.argmax(similarities)\n",
    "    predicted_label = valid_gallery_labels[max_idx]\n",
    "    is_recognized = max_similarity > threshold\n",
    "\n",
    "    if np.isnan(max_similarity):\n",
    "         return \"unknown\", 0.0, False\n",
    "\n",
    "    return predicted_label, float(max_similarity), bool(is_recognized)\n",
    "\n",
    "def cosine_similarity_top_n(query_embedding, gallery_embeddings, gallery_labels, top_n=5):\n",
    "    \"\"\"\n",
    "    Mengembalikan Top-N label beserta skor similarity-nya.\n",
    "    \"\"\"\n",
    "    if query_embedding is None or not gallery_embeddings:\n",
    "        return [], False\n",
    "\n",
    "    query_embedding = np.array(query_embedding)\n",
    "    query_norm = np.linalg.norm(query_embedding)\n",
    "    if query_norm == 0:\n",
    "        return [], False\n",
    "    query_embedding = query_embedding / query_norm\n",
    "\n",
    "    # Hitung similarity untuk semua kandidat di galeri\n",
    "    scores = []\n",
    "    for gallery_emb, label in zip(gallery_embeddings, gallery_labels):\n",
    "        gallery_emb = np.array(gallery_emb)\n",
    "        gallery_norm = np.linalg.norm(gallery_emb)\n",
    "        if gallery_norm > 0:\n",
    "            gallery_emb = gallery_emb / gallery_norm\n",
    "            sim = np.dot(query_embedding, gallery_emb)\n",
    "            scores.append((label, sim))\n",
    "\n",
    "    # Urutkan dari similarity terbesar ke terkecil\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Ambil Top-N\n",
    "    # Catatan: Ini logic \"Nearest Neighbor\". Jika ada banyak foto 'subject_a' di galeri,\n",
    "    # Top-5 bisa jadi ['a', 'a', 'a', 'b', 'c'].\n",
    "    # Jika ground_truth 'a' ada di list ini, maka hitungannya benar.\n",
    "    top_results = scores[:top_n]\n",
    "    \n",
    "    return top_results\n",
    "\n",
    "\n",
    "print(\"Fungsi-fungsi utilitas siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4a95e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mempersiapkan data latih dari galeri...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb5e826c6674edb9d2490f39b9f9dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Membangun Dataset Latih:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset latih siap dengan 55 sampel.\n",
      "Subjek yang ditemukan: ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k']\n",
      "\n",
      "Melatih model K-Nearest Neighbors (KNN)...\n",
      "Model KNN selesai dilatih.\n",
      "Melatih model Support Vector Machine (SVM)...\n",
      "Model SVM selesai dilatih.\n",
      "Model KNN, SVM, dan LabelEncoder baru berhasil disimpan di: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\models_v6.4.3.2_tuned\n",
      "\n",
      "Mempersiapkan gallery embeddings untuk cosine similarity...\n",
      "Cache gallery embeddings tidak ditemukan, membuat ulang...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660653f149bb4d1597a3fecf78dc4098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Membangun Gallery Embeddings:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache gallery embeddings disimpan.\n",
      "Gallery embeddings siap dengan 55 sampel.\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 3: LATIH CLASSIFIER & PERSIAPAN GALERI =============\n",
    "\n",
    "# --- Selalu Latih Classifier dari Galeri ---\n",
    "print(\"Mempersiapkan data latih dari galeri...\")\n",
    "X_train = []\n",
    "y_train_labels = []\n",
    "gallery_files = glob.glob(os.path.join(GALLERY_PATH, '*.jpg')) # Sesuaikan ekstensi\n",
    "\n",
    "if not gallery_files:\n",
    "     print(f\"ERROR: Tidak ada file ditemukan di {GALLERY_PATH}. Pelatihan dibatalkan.\")\n",
    "     sys.exit()\n",
    "\n",
    "for g_file in tqdm(gallery_files, desc=\"Membangun Dataset Latih\"):\n",
    "    subject_id = os.path.basename(g_file).split('_')[0]\n",
    "    embedding = get_embedding(g_file) # Gunakan fungsi get_embedding\n",
    "    if embedding is not None:\n",
    "        X_train.append(embedding)\n",
    "        y_train_labels.append(subject_id)\n",
    "\n",
    "if not X_train:\n",
    "     print(\"ERROR: Tidak ada embedding yang berhasil diekstrak dari galeri. Pelatihan dibatalkan.\")\n",
    "     sys.exit()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_labels)\n",
    "labels = le.classes_\n",
    "print(f\"\\nDataset latih siap dengan {len(X_train)} sampel.\")\n",
    "print(f\"Subjek yang ditemukan: {labels}\")\n",
    "\n",
    "# Latih KNN\n",
    "print(\"\\nMelatih model K-Nearest Neighbors (KNN)...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1, weights='distance', metric='euclidean')\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"Model KNN selesai dilatih.\")\n",
    "\n",
    "# Latih SVM\n",
    "print(\"Melatih model Support Vector Machine (SVM)...\")\n",
    "svm_model = SVC(kernel='linear', probability=True, C=1000.0)\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(\"Model SVM selesai dilatih.\")\n",
    "\n",
    "# >>>>> PERUBAHAN PATH PENYIMPANAN <<<<<\n",
    "knn_model_path_new = os.path.join(NEW_MODELS_PATH, 'knn_model_tuned.pkl')\n",
    "svm_model_path_new = os.path.join(NEW_MODELS_PATH, 'svm_model_tuned.pkl')\n",
    "le_path_new = os.path.join(NEW_MODELS_PATH, 'label_encoder.pkl')\n",
    "\n",
    "with open(knn_model_path_new, 'wb') as f: pickle.dump(knn_model, f)\n",
    "with open(svm_model_path_new, 'wb') as f: pickle.dump(svm_model, f)\n",
    "with open(le_path_new, 'wb') as f: pickle.dump(le, f)\n",
    "print(f\"Model KNN, SVM, dan LabelEncoder baru berhasil disimpan di: {NEW_MODELS_PATH}\")\n",
    "\n",
    "\n",
    "# ============== PERSIAPAN GALLERY EMBEDDINGS UNTUK COSINE SIMILARITY =============\n",
    "print(\"\\nMempersiapkan gallery embeddings untuk cosine similarity...\")\n",
    "gallery_embeddings = []\n",
    "gallery_labels = []\n",
    "gallery_files_cosine = glob.glob(os.path.join(GALLERY_PATH, '*.jpg')) # Sesuaikan ekstensi\n",
    "\n",
    "if not gallery_files_cosine:\n",
    "     print(f\"ERROR: Tidak ada file ditemukan di {GALLERY_PATH} untuk cosine similarity.\")\n",
    "     sys.exit()\n",
    "\n",
    "# Coba muat cache embedding galeri jika ada untuk mempercepat\n",
    "gallery_cache_path = os.path.join(CACHE_PATH, 'gallery_embeddings_cache.pkl')\n",
    "try:\n",
    "    with open(gallery_cache_path, 'rb') as f:\n",
    "        gallery_embeddings, gallery_labels = pickle.load(f)\n",
    "    print(f\"Cache gallery embeddings dimuat ({len(gallery_embeddings)} sampel).\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Cache gallery embeddings tidak ditemukan, membuat ulang...\")\n",
    "    for g_file in tqdm(gallery_files_cosine, desc=\"Membangun Gallery Embeddings\"):\n",
    "        subject_id = os.path.basename(g_file).split('_')[0]\n",
    "        embedding = get_embedding(g_file)\n",
    "        if embedding is not None:\n",
    "            gallery_embeddings.append(embedding)\n",
    "            gallery_labels.append(subject_id)\n",
    "    # Simpan ke cache\n",
    "    try:\n",
    "        with open(gallery_cache_path, 'wb') as f:\n",
    "            pickle.dump((gallery_embeddings, gallery_labels), f)\n",
    "        print(\"Cache gallery embeddings disimpan.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal menyimpan cache gallery embeddings: {e}\")\n",
    "\n",
    "if not gallery_embeddings:\n",
    "     print(\"ERROR: Tidak ada embedding galeri yang berhasil dibuat untuk cosine similarity.\")\n",
    "     sys.exit()\n",
    "else:\n",
    "     print(f\"Gallery embeddings siap dengan {len(gallery_embeddings)} sampel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5bf3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Berhasil memuat 1364 fitur probe dari d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\features_v6.4\\probe_features_v6.4.json\n",
      "\n",
      "=== DEBUG: Memeriksa struktur data pertama ===\n",
      "\n",
      "Tipe embedding_original: <class 'list'>\n",
      "Panjang embedding_original: 512\n",
      "\n",
      "Tipe embedding_restored: <class 'list'>\n",
      "Panjang embedding_restored: 512\n",
      "==================================================\n",
      "\n",
      "Memulai proses rekognisi untuk ORIGINAL dan RESTORED...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959784989d5b4ab7a0d64b87e895e605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Melakukan Rekognisi:   0%|          | 0/1364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "                    STATISTIK EMBEDDING                     \n",
      "============================================================\n",
      "Total data probe               : 1364\n",
      "Restorasi berhasil             : 1364 (100.0%)\n",
      "\n",
      "Embedding ORIGINAL valid       : 1351 (99.0%)\n",
      "Embedding RESTORED valid       : 1364 (100.0%)\n",
      "Kedua embedding valid          : 1351 (99.0%)\n",
      "============================================================\n",
      "\n",
      "Hasil rekognisi berhasil disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.3.2_recognition\\recognition_results_v6.4.3.2_comparison.json\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 4 (REVISI LENGKAP & FIXED): MUAT FITUR PROBE & LAKUKAN REKOGNISI =============\n",
    "# Versi ini menganalisis KEDUA embedding: original dan restored\n",
    "\n",
    "features_file_path = os.path.join(PROBE_FEATURES_PATH, 'probe_features_v6.4.json')\n",
    "try:\n",
    "    with open(features_file_path, 'r', encoding='utf-8') as f:\n",
    "        probe_features = json.load(f)\n",
    "    print(f\"\\nBerhasil memuat {len(probe_features)} fitur probe dari {features_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File fitur probe tidak ditemukan di {features_file_path}.\")\n",
    "    probe_features = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"ERROR: Gagal mem-parsing file JSON fitur probe: {features_file_path}.\")\n",
    "    probe_features = []\n",
    "\n",
    "# >>>>> DEBUG: Memeriksa struktur data pertama <<<<<\n",
    "if probe_features:\n",
    "    print(\"\\n=== DEBUG: Memeriksa struktur data pertama ===\")\n",
    "    first_entry = probe_features[0]\n",
    "    # print(f\"Keys dalam entry pertama: {first_entry.keys()}\")\n",
    "    \n",
    "    emb_orig = first_entry.get('embedding_original')\n",
    "    emb_rest = first_entry.get('embedding_restored')\n",
    "    \n",
    "    print(f\"\\nTipe embedding_original: {type(emb_orig)}\")\n",
    "    if emb_orig and isinstance(emb_orig, list):\n",
    "        print(f\"Panjang embedding_original: {len(emb_orig)}\")\n",
    "    \n",
    "    print(f\"\\nTipe embedding_restored: {type(emb_rest)}\")\n",
    "    if emb_rest and isinstance(emb_rest, list):\n",
    "        print(f\"Panjang embedding_restored: {len(emb_rest)}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "recognition_results = []\n",
    "\n",
    "# Counters untuk statistik\n",
    "stats = {\n",
    "    'total': 0,\n",
    "    'original_valid': 0,\n",
    "    'restored_valid': 0,\n",
    "    'both_valid': 0,\n",
    "    'restoration_succeeded': 0\n",
    "}\n",
    "\n",
    "if not probe_features:\n",
    "    print(\"Tidak ada fitur probe untuk diproses.\")\n",
    "else:\n",
    "    print(\"\\nMemulai proses rekognisi untuk ORIGINAL dan RESTORED...\")\n",
    "    \n",
    "    for idx, feature_entry in enumerate(tqdm(probe_features, desc=\"Melakukan Rekognisi\")):\n",
    "        stats['total'] += 1\n",
    "        \n",
    "        # >>>>> AMBIL KEDUA EMBEDDING <<<<<\n",
    "        probe_embedding_original = feature_entry.get('embedding_original')\n",
    "        probe_embedding_restored = feature_entry.get('embedding_restored')\n",
    "        \n",
    "        ground_truth = feature_entry.get('ground_truth', 'unknown')\n",
    "        filename = feature_entry.get('file', 'unknown')\n",
    "        metadata = feature_entry.get('metadata', {})\n",
    "        restoration_succeeded = feature_entry.get('restoration_succeeded', False)\n",
    "        \n",
    "        if restoration_succeeded:\n",
    "            stats['restoration_succeeded'] += 1\n",
    "        \n",
    "        # >>>>> STRUKTUR RESULT ENTRY <<<<<\n",
    "        result_entry = {\n",
    "            'file': filename,\n",
    "            'ground_truth': ground_truth,\n",
    "            'metadata': metadata,\n",
    "            'restoration_succeeded': restoration_succeeded,\n",
    "            \n",
    "            # Default values (akan diupdate fungsi helper)\n",
    "            'embedding_original_found': False,\n",
    "            'embedding_restored_found': False\n",
    "        }\n",
    "        \n",
    "        # >>>>> FUNGSI HELPER UNTUK PREDIKSI (TOP-N) <<<<<\n",
    "        def predict_all_models(embedding, suffix=''):\n",
    "            results = {}\n",
    "            \n",
    "            # --- Validasi Embedding ---\n",
    "            has_valid = False\n",
    "            if isinstance(embedding, list) and len(embedding) > 0: has_valid = True\n",
    "            elif isinstance(embedding, np.ndarray) and embedding.size > 0: has_valid = True\n",
    "            \n",
    "            if not has_valid:\n",
    "                for k in range(1, 6):\n",
    "                    results[f'knn_top{k}{suffix}'] = False\n",
    "                    results[f'svm_top{k}{suffix}'] = False\n",
    "                    results[f'cosine_top{k}{suffix}'] = False\n",
    "                results[f'embedding{suffix}_found'] = False\n",
    "                # Tetap isi prediction single value agar tidak error saat akses key nanti\n",
    "                results[f'prediction_knn{suffix}'] = 'unknown'\n",
    "                results[f'prediction_svm{suffix}'] = 'unknown'\n",
    "                results[f'prediction_cosine{suffix}'] = 'unknown'\n",
    "                return results\n",
    "\n",
    "            results[f'embedding{suffix}_found'] = True\n",
    "            embedding_np = np.array(embedding).reshape(1, -1)\n",
    "            \n",
    "            # 1. PREDIKSI KNN\n",
    "            try:\n",
    "                knn_probs = knn_model.predict_proba(embedding_np)[0]\n",
    "                top_k_indices = np.argsort(knn_probs)[::-1][:5]\n",
    "                top_k_labels = le.inverse_transform(top_k_indices)\n",
    "                for k in range(1, 6):\n",
    "                    is_correct = ground_truth in top_k_labels[:k]\n",
    "                    results[f'knn_top{k}{suffix}'] = is_correct\n",
    "                results[f'prediction_knn{suffix}'] = top_k_labels[0]\n",
    "            except Exception:\n",
    "                for k in range(1, 6): results[f'knn_top{k}{suffix}'] = False\n",
    "                results[f'prediction_knn{suffix}'] = 'unknown'\n",
    "\n",
    "            # 2. PREDIKSI SVM\n",
    "            try:\n",
    "                svm_probs = svm_model.predict_proba(embedding_np)[0]\n",
    "                top_k_indices = np.argsort(svm_probs)[::-1][:5]\n",
    "                top_k_labels = le.inverse_transform(top_k_indices)\n",
    "                for k in range(1, 6):\n",
    "                    is_correct = ground_truth in top_k_labels[:k]\n",
    "                    results[f'svm_top{k}{suffix}'] = is_correct\n",
    "                results[f'prediction_svm{suffix}'] = top_k_labels[0]\n",
    "            except Exception:\n",
    "                for k in range(1, 6): results[f'svm_top{k}{suffix}'] = False\n",
    "                results[f'prediction_svm{suffix}'] = 'unknown'\n",
    "\n",
    "            # 3. PREDIKSI COSINE\n",
    "            try:\n",
    "                top_n_results = cosine_similarity_top_n(embedding, gallery_embeddings, gallery_labels, top_n=5)\n",
    "                top_k_labels = [label for label, score in top_n_results]\n",
    "                for k in range(1, 6):\n",
    "                    if len(top_k_labels) >= k: is_correct = ground_truth in top_k_labels[:k]\n",
    "                    else: is_correct = ground_truth in top_k_labels\n",
    "                    results[f'cosine_top{k}{suffix}'] = is_correct\n",
    "\n",
    "                if top_n_results:\n",
    "                    results[f'prediction_cosine{suffix}'] = top_n_results[0][0]\n",
    "                    results[f'similarity_cosine{suffix}'] = top_n_results[0][1]\n",
    "                else:\n",
    "                    results[f'prediction_cosine{suffix}'] = 'unknown'\n",
    "            except Exception:\n",
    "                for k in range(1, 6): results[f'cosine_top{k}{suffix}'] = False\n",
    "                results[f'prediction_cosine{suffix}'] = 'unknown'\n",
    "\n",
    "            return results\n",
    "        \n",
    "        # ======================================================================\n",
    "        # >>>>> BAGIAN YANG HILANG (EKSEKUSI FUNGSI) <<<<<\n",
    "        # ======================================================================\n",
    "        \n",
    "        # 1. Proses Original\n",
    "        original_results = predict_all_models(probe_embedding_original, '_original')\n",
    "        result_entry.update(original_results)\n",
    "        if original_results.get('embedding_original_found'):\n",
    "            stats['original_valid'] += 1\n",
    "            \n",
    "        # 2. Proses Restored\n",
    "        restored_results = predict_all_models(probe_embedding_restored, '_restored')\n",
    "        result_entry.update(restored_results)\n",
    "        if restored_results.get('embedding_restored_found'):\n",
    "            stats['restored_valid'] += 1\n",
    "            \n",
    "        # 3. Hitung Both Valid\n",
    "        if original_results.get('embedding_original_found') and restored_results.get('embedding_restored_found'):\n",
    "            stats['both_valid'] += 1\n",
    "            \n",
    "        recognition_results.append(result_entry)\n",
    "    \n",
    "    # >>>>> TAMPILKAN STATISTIK <<<<<\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"STATISTIK EMBEDDING\".center(60))\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total data probe               : {stats['total']}\")\n",
    "    print(f\"Restorasi berhasil             : {stats['restoration_succeeded']} ({stats['restoration_succeeded']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"\\nEmbedding ORIGINAL valid       : {stats['original_valid']} ({stats['original_valid']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"Embedding RESTORED valid       : {stats['restored_valid']} ({stats['restored_valid']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"Kedua embedding valid          : {stats['both_valid']} ({stats['both_valid']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # --- Simpan Hasil Rekognisi ---\n",
    "    results_file_path = os.path.join(RESULTS_PATH, 'recognition_results_v6.4.3.2_comparison.json')\n",
    "    try:\n",
    "        with open(results_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(recognition_results, f, indent=4, cls=NumpyJSONEncoder)\n",
    "        print(f\"Hasil rekognisi berhasil disimpan ke: {results_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saat menyimpan hasil rekognisi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367660ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "               MEMULAI ANALISIS PERBANDINGAN ORIGINAL VS RESTORED               \n",
      "================================================================================\n",
      "\n",
      "Data dengan embedding ORIGINAL valid: 1351\n",
      "Data dengan embedding RESTORED valid: 1364\n",
      "\n",
      "================================================================================\n",
      "               BAGIAN 1: CLASSIFICATION REPORT & CONFUSION MATRIX               \n",
      "================================================================================\n",
      "\n",
      ">>> EMBEDDING ORIGINAL <<<\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                            KNN - Original Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.17      1.00      0.29       124\n",
      "           b       0.95      0.46      0.62       124\n",
      "           c       0.97      0.32      0.48       122\n",
      "           d       1.00      0.48      0.64       124\n",
      "           e       1.00      0.41      0.58       123\n",
      "           f       0.47      0.34      0.39       120\n",
      "           g       0.80      0.49      0.61       124\n",
      "           h       0.79      0.33      0.47       123\n",
      "           i       1.00      0.34      0.51       121\n",
      "           j       1.00      0.60      0.75       124\n",
      "           k       0.99      0.64      0.78       122\n",
      "\n",
      "    accuracy                           0.49      1351\n",
      "   macro avg       0.83      0.49      0.56      1351\n",
      "weighted avg       0.83      0.49      0.56      1351\n",
      "\n",
      "Confusion matrix disimpan ke: knn_-_original_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                            SVM - Original Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.25      0.99      0.39       124\n",
      "           b       0.98      0.34      0.50       124\n",
      "           c       1.00      0.30      0.46       122\n",
      "           d       1.00      0.40      0.57       124\n",
      "           e       1.00      0.40      0.57       123\n",
      "           f       0.66      0.41      0.51       120\n",
      "           g       0.26      0.73      0.38       124\n",
      "           h       0.77      0.43      0.55       123\n",
      "           i       1.00      0.31      0.48       121\n",
      "           j       1.00      0.53      0.69       124\n",
      "           k       1.00      0.62      0.77       122\n",
      "\n",
      "    accuracy                           0.50      1351\n",
      "   macro avg       0.81      0.50      0.53      1351\n",
      "weighted avg       0.81      0.50      0.53      1351\n",
      "\n",
      "Confusion matrix disimpan ke: svm_-_original_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                     Cosine Similarity - Original Embedding                     \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.19      1.00      0.32       124\n",
      "           b       0.92      0.49      0.64       124\n",
      "           c       0.92      0.39      0.54       122\n",
      "           d       1.00      0.55      0.71       124\n",
      "           e       0.98      0.44      0.61       123\n",
      "           f       0.93      0.33      0.48       120\n",
      "           g       0.58      0.63      0.60       124\n",
      "           h       0.86      0.41      0.55       123\n",
      "           i       1.00      0.45      0.62       121\n",
      "           j       0.92      0.69      0.79       124\n",
      "           k       1.00      0.69      0.82       122\n",
      "\n",
      "    accuracy                           0.55      1351\n",
      "   macro avg       0.85      0.55      0.61      1351\n",
      "weighted avg       0.85      0.55      0.61      1351\n",
      "\n",
      "Confusion matrix disimpan ke: cosine_similarity_-_original_embedding.png\n",
      "================================================================================\n",
      "\n",
      ">>> EMBEDDING RESTORED <<<\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                            KNN - Restored Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.39      0.97      0.56       124\n",
      "           b       0.79      0.55      0.65       124\n",
      "           c       0.87      0.27      0.42       124\n",
      "           d       0.93      0.80      0.86       124\n",
      "           e       0.91      0.56      0.70       124\n",
      "           f       0.33      0.79      0.47       124\n",
      "           g       0.72      0.69      0.70       124\n",
      "           h       0.64      0.44      0.52       124\n",
      "           i       0.92      0.39      0.55       124\n",
      "           j       0.97      0.69      0.80       124\n",
      "           k       0.91      0.80      0.85       124\n",
      "\n",
      "    accuracy                           0.63      1364\n",
      "   macro avg       0.76      0.63      0.64      1364\n",
      "weighted avg       0.76      0.63      0.64      1364\n",
      "\n",
      "Confusion matrix disimpan ke: knn_-_restored_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                            SVM - Restored Embedding                            \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.67      0.87      0.76       124\n",
      "           b       0.80      0.54      0.64       124\n",
      "           c       0.97      0.23      0.38       124\n",
      "           d       0.95      0.64      0.76       124\n",
      "           e       0.95      0.49      0.65       124\n",
      "           f       0.38      0.77      0.51       124\n",
      "           g       0.30      0.90      0.44       124\n",
      "           h       0.67      0.45      0.54       124\n",
      "           i       0.95      0.31      0.47       124\n",
      "           j       0.94      0.68      0.79       124\n",
      "           k       0.97      0.77      0.86       124\n",
      "\n",
      "    accuracy                           0.61      1364\n",
      "   macro avg       0.78      0.61      0.62      1364\n",
      "weighted avg       0.78      0.61      0.62      1364\n",
      "\n",
      "Confusion matrix disimpan ke: svm_-_restored_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "                     Cosine Similarity - Restored Embedding                     \n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.37      0.90      0.53       124\n",
      "           b       0.73      0.67      0.70       124\n",
      "           c       0.73      0.52      0.61       124\n",
      "           d       0.84      0.79      0.81       124\n",
      "           e       0.88      0.55      0.68       124\n",
      "           f       0.56      0.57      0.57       124\n",
      "           g       0.65      0.73      0.68       124\n",
      "           h       0.77      0.45      0.57       124\n",
      "           i       0.83      0.52      0.64       124\n",
      "           j       0.74      0.79      0.76       124\n",
      "           k       0.82      0.79      0.81       124\n",
      "\n",
      "    accuracy                           0.66      1364\n",
      "   macro avg       0.72      0.66      0.67      1364\n",
      "weighted avg       0.72      0.66      0.67      1364\n",
      "\n",
      "Confusion matrix disimpan ke: cosine_similarity_-_restored_embedding.png\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "           BAGIAN 2: TABEL PERBANDINGAN KINERJA BERDASARKAN SKENARIO            \n",
      "================================================================================\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "                                 Tabel Perbandingan Kinerja - K-Nearest Neighbors (KNN)                                 \n",
      "========================================================================================================================\n",
      "              Skenario           Metode Akurasi (Top-1) Presisi Recall F1-Score Peningkatan Akurasi\n",
      "    Jarak Dekat (< 7m)  Tanpa Restorasi          84.10%  90.00% 83.97%   85.09%                   -\n",
      "    Jarak Dekat (< 7m) Dengan Restorasi          77.27%  89.61% 77.27%   79.91%              -8.12%\n",
      "Jarak Menengah (7-12m)  Tanpa Restorasi          56.04%  80.11% 55.98%   59.73%                   -\n",
      "Jarak Menengah (7-12m) Dengan Restorasi          72.95%  83.58% 72.95%   72.48%             +30.19%\n",
      "   Jarak Jauh (>= 12m)  Tanpa Restorasi          11.30%  39.05% 11.20%    5.48%                   -\n",
      "   Jarak Jauh (>= 12m) Dengan Restorasi          41.53%  53.19% 41.53%   39.57%            +267.61%\n",
      "       Ketinggian 1.5m  Tanpa Restorasi          58.82%  87.95% 58.77%   65.67%                   -\n",
      "       Ketinggian 1.5m Dengan Restorasi          65.69%  77.59% 65.69%   66.30%             +11.67%\n",
      "         Ketinggian 3m  Tanpa Restorasi          57.23%  85.17% 57.15%   63.21%                   -\n",
      "         Ketinggian 3m Dengan Restorasi          70.38%  79.57% 70.38%   70.91%             +22.99%\n",
      "         Ketinggian 4m  Tanpa Restorasi          49.12%  83.05% 49.17%   54.75%                   -\n",
      "         Ketinggian 4m Dengan Restorasi          68.62%  79.42% 68.62%   68.92%             +39.71%\n",
      "         Ketinggian 5m  Tanpa Restorasi          31.33%  71.88% 30.86%   33.61%                   -\n",
      "         Ketinggian 5m Dengan Restorasi          48.09%  67.01% 48.09%   48.17%             +53.53%\n",
      "        Semua Data Uji  Tanpa Restorasi          49.22%  83.08% 49.12%   55.60%                   -\n",
      "        Semua Data Uji Dengan Restorasi          63.20%  76.14% 63.20%   64.28%             +28.39%\n",
      "========================================================================================================================\n",
      "\n",
      "Tabel K-Nearest Neighbors (KNN) disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.3.2_recognition\\comparison_table_knn_v6.4.3.2.csv\n",
      "\n",
      "========================================================================================================================\n",
      "                               Tabel Perbandingan Kinerja - Support Vector Machine (SVM)                                \n",
      "========================================================================================================================\n",
      "              Skenario           Metode Akurasi (Top-1) Presisi Recall F1-Score Peningkatan Akurasi\n",
      "    Jarak Dekat (< 7m)  Tanpa Restorasi          84.33%  89.71% 84.30%   84.97%                   -\n",
      "    Jarak Dekat (< 7m) Dengan Restorasi          76.36%  86.55% 76.36%   77.51%              -9.45%\n",
      "Jarak Menengah (7-12m)  Tanpa Restorasi          55.35%  80.15% 55.29%   56.74%                   -\n",
      "Jarak Menengah (7-12m) Dengan Restorasi          70.68%  83.34% 70.68%   70.22%             +27.69%\n",
      "   Jarak Jauh (>= 12m)  Tanpa Restorasi          12.97%  29.48% 12.82%    4.86%                   -\n",
      "   Jarak Jauh (>= 12m) Dengan Restorasi          36.98%  59.73% 36.98%   35.61%            +185.13%\n",
      "       Ketinggian 1.5m  Tanpa Restorasi          59.41%  85.35% 59.35%   63.85%                   -\n",
      "       Ketinggian 1.5m Dengan Restorasi          62.17%  79.40% 62.17%   63.97%              +4.64%\n",
      "         Ketinggian 3m  Tanpa Restorasi          58.11%  83.30% 57.99%   60.96%                   -\n",
      "         Ketinggian 3m Dengan Restorasi          68.33%  79.79% 68.33%   68.68%             +17.58%\n",
      "         Ketinggian 4m  Tanpa Restorasi          52.35%  81.87% 52.39%   55.82%                   -\n",
      "         Ketinggian 4m Dengan Restorasi          64.52%  80.70% 64.52%   65.41%             +23.23%\n",
      "         Ketinggian 5m  Tanpa Restorasi          28.31%  59.74% 27.97%   26.17%                   -\n",
      "         Ketinggian 5m Dengan Restorasi          47.21%  72.09% 47.21%   46.24%             +66.76%\n",
      "        Semua Data Uji  Tanpa Restorasi          49.67%  81.00% 49.58%   53.33%                   -\n",
      "        Semua Data Uji Dengan Restorasi          60.56%  77.69% 60.56%   61.87%             +21.93%\n",
      "========================================================================================================================\n",
      "\n",
      "Tabel Support Vector Machine (SVM) disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.3.2_recognition\\comparison_table_svm_v6.4.3.2.csv\n",
      "\n",
      "========================================================================================================================\n",
      "                                     Tabel Perbandingan Kinerja - Cosine Similarity                                     \n",
      "========================================================================================================================\n",
      "              Skenario           Metode Akurasi (Top-1) Presisi Recall F1-Score Peningkatan Akurasi\n",
      "    Jarak Dekat (< 7m)  Tanpa Restorasi          89.40%  92.36% 89.18%   89.69%                   -\n",
      "    Jarak Dekat (< 7m) Dengan Restorasi          78.64%  90.05% 78.64%   81.32%             -12.04%\n",
      "Jarak Menengah (7-12m)  Tanpa Restorasi          65.15%  83.07% 65.10%   67.54%                   -\n",
      "Jarak Menengah (7-12m) Dengan Restorasi          76.59%  81.53% 76.59%   76.92%             +17.56%\n",
      "   Jarak Jauh (>= 12m)  Tanpa Restorasi          15.06%  38.51% 14.94%   11.03%                   -\n",
      "   Jarak Jauh (>= 12m) Dengan Restorasi          45.66%  49.11% 45.66%   44.92%            +203.14%\n",
      "       Ketinggian 1.5m  Tanpa Restorasi          62.35%  87.80% 62.31%   68.12%                   -\n",
      "       Ketinggian 1.5m Dengan Restorasi          69.21%  75.37% 69.21%   69.55%             +10.99%\n",
      "         Ketinggian 3m  Tanpa Restorasi          63.72%  86.53% 63.63%   68.28%                   -\n",
      "         Ketinggian 3m Dengan Restorasi          77.13%  79.12% 77.13%   77.26%             +21.05%\n",
      "         Ketinggian 4m  Tanpa Restorasi          54.71%  84.78% 54.75%   59.68%                   -\n",
      "         Ketinggian 4m Dengan Restorasi          72.14%  76.11% 72.14%   72.18%             +31.87%\n",
      "         Ketinggian 5m  Tanpa Restorasi          39.76%  71.92% 39.11%   42.13%                   -\n",
      "         Ketinggian 5m Dengan Restorasi          46.63%  58.09% 46.63%   46.21%             +17.28%\n",
      "        Semua Data Uji  Tanpa Restorasi          55.22%  84.70% 55.11%   60.86%                   -\n",
      "        Semua Data Uji Dengan Restorasi          66.28%  72.07% 66.28%   66.92%             +20.02%\n",
      "========================================================================================================================\n",
      "\n",
      "Tabel Cosine Similarity disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.3.2_recognition\\comparison_table_cosine_v6.4.3.2.csv\n",
      "\n",
      "================================================================================\n",
      "                     BAGIAN 3: SUMMARY PENINGKATAN KINERJA                      \n",
      "================================================================================\n",
      "\n",
      "                       Model Akurasi Original Akurasi Restored Peningkatan\n",
      "   K-Nearest Neighbors (KNN)           49.22%           63.20%      +28.4%\n",
      "Support Vector Machine (SVM)           49.67%           60.56%      +21.9%\n",
      "           Cosine Similarity           55.22%           66.28%      +20.0%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Summary peningkatan disimpan ke: d:\\UNSRI_DATA\\_SKRIPSI\\PROGRAM\\v1\\pipeline_skripsi\\results_v6.4.3.2_recognition\\summary_improvement_v3.csv\n",
      "\n",
      "================================================================================\n",
      "                                ANALISIS SELESAI                                \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============== LANGKAH 5: ANALISIS HASIL REKOGNISI (ORIGINAL VS RESTORED) =============\n",
    "\n",
    "if not recognition_results:\n",
    "    print(\"\\nTidak ada hasil rekognisi untuk dianalisis.\")\n",
    "else:\n",
    "    df_results = pd.DataFrame(recognition_results)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MEMULAI ANALISIS PERBANDINGAN ORIGINAL VS RESTORED\".center(80))\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    # >>>>> ANALISIS UNTUK ORIGINAL <<<<<\n",
    "    df_original = df_results[df_results['embedding_original_found'] == True].copy()\n",
    "\n",
    "    # >>>>> ANALISIS UNTUK RESTORED <<<<<\n",
    "    df_restored = df_results[df_results['embedding_restored_found'] == True].copy()\n",
    "\n",
    "    if df_original.empty and df_restored.empty:\n",
    "        print(\"Tidak ada hasil rekognisi yang memiliki embedding untuk dianalisis.\")\n",
    "    else:\n",
    "        # Prepare metadata columns untuk kedua dataframe\n",
    "        for df in [df_original, df_restored]:\n",
    "            if not df.empty:\n",
    "                df['distance_m'] = df['metadata'].apply(lambda x: x.get('distance_m') if isinstance(x, dict) else None)\n",
    "                df['height_m'] = df['metadata'].apply(lambda x: x.get('height_m') if isinstance(x, dict) else None)\n",
    "\n",
    "        print(f\"Data dengan embedding ORIGINAL valid: {len(df_original)}\")\n",
    "        print(f\"Data dengan embedding RESTORED valid: {len(df_restored)}\")\n",
    "\n",
    "        # >>>>> FUNGSI HELPER UNTUK ANALISIS <<<<<\n",
    "        def print_classification_report(title, y_true, y_pred, labels_list, save_cm=True):\n",
    "            \"\"\"Cetak classification report dan confusion matrix\"\"\"\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"{title}\".center(80))\n",
    "            print(f\"{'='*80}\")\n",
    "            print(classification_report(y_true, y_pred, labels=labels_list, zero_division=0))\n",
    "\n",
    "            if save_cm:\n",
    "                try:\n",
    "                    cm = confusion_matrix(y_true, y_pred, labels=labels_list)\n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    sns.heatmap(cm, annot=True, fmt='d', cmap='viridis',\n",
    "                                xticklabels=labels_list, yticklabels=labels_list)\n",
    "                    plt.title(title)\n",
    "                    plt.ylabel('Label Sebenarnya (Ground Truth)')\n",
    "                    plt.xlabel('Label Prediksi')\n",
    "                    plot_filename = f\"{title.replace(' ', '_').replace('(', '').replace(')', '').lower()}.png\"\n",
    "                    plot_path = os.path.join(RESULTS_PATH, plot_filename)\n",
    "                    plt.savefig(plot_path, dpi=100, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(f\"Confusion matrix disimpan ke: {plot_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Gagal membuat confusion matrix: {e}\")\n",
    "            print(\"=\"*80)\n",
    "\n",
    "        def calculate_metrics(df, suffix, labels_list):\n",
    "            \"\"\"Hitung metrik untuk satu set data\"\"\"\n",
    "            metrics = {}\n",
    "            for model in ['knn', 'svm', 'cosine']:\n",
    "                # === PERBAIKAN DI SINI ===\n",
    "                # Sebelumnya: f'is_correct_{model}{suffix}' (Salah, kolom ini tidak ada)\n",
    "                # Menjadi:    f'{model}_top1{suffix}'      (Benar, sesuai output Langkah 4)\n",
    "                is_correct_col = f'{model}_top1{suffix}' \n",
    "                \n",
    "                prediction_col = f'prediction_{model}{suffix}'\n",
    "\n",
    "                if is_correct_col in df.columns:\n",
    "                    y_true = df['ground_truth']\n",
    "                    y_pred = df[prediction_col]\n",
    "\n",
    "                    accuracy = df[is_correct_col].mean()\n",
    "                    \n",
    "                    # Hitung Precision, Recall, F1\n",
    "                    precision = precision_score(y_true, y_pred, average='macro', zero_division=0, labels=labels_list)\n",
    "                    recall = recall_score(y_true, y_pred, average='macro', zero_division=0, labels=labels_list)\n",
    "                    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0, labels=labels_list)\n",
    "\n",
    "                    metrics[model] = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1\n",
    "                    }\n",
    "            return metrics\n",
    "\n",
    "        # >>>>> ANALISIS OVERALL (CONFUSION MATRIX & REPORT) <<<<<\n",
    "\n",
    "        # Get labels yang ada di data\n",
    "        labels_original = sorted(df_original['ground_truth'].unique()) if not df_original.empty else []\n",
    "        labels_restored = sorted(df_restored['ground_truth'].unique()) if not df_restored.empty else []\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"BAGIAN 1: CLASSIFICATION REPORT & CONFUSION MATRIX\".center(80))\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # --- ORIGINAL ---\n",
    "        if not df_original.empty:\n",
    "            print(\"\\n>>> EMBEDDING ORIGINAL <<<\\n\")\n",
    "            print_classification_report(\"KNN - Original Embedding\", df_original['ground_truth'], df_original['prediction_knn_original'], labels_original)\n",
    "            print_classification_report(\"SVM - Original Embedding\", df_original['ground_truth'], df_original['prediction_svm_original'], labels_original)\n",
    "            print_classification_report(\"Cosine Similarity - Original Embedding\", df_original['ground_truth'], df_original['prediction_cosine_original'], labels_original)\n",
    "\n",
    "        # --- RESTORED ---\n",
    "        if not df_restored.empty:\n",
    "            print(\"\\n>>> EMBEDDING RESTORED <<<\\n\")\n",
    "            print_classification_report(\"KNN - Restored Embedding\", df_restored['ground_truth'], df_restored['prediction_knn_restored'], labels_restored)\n",
    "            print_classification_report(\"SVM - Restored Embedding\", df_restored['ground_truth'], df_restored['prediction_svm_restored'], labels_restored)\n",
    "            print_classification_report(\"Cosine Similarity - Restored Embedding\", df_restored['ground_truth'], df_restored['prediction_cosine_restored'], labels_restored)\n",
    "\n",
    "        # >>>>> BAGIAN 2: TABEL PERBANDINGAN BERDASARKAN SKENARIO <<<<<\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"BAGIAN 2: TABEL PERBANDINGAN KINERJA BERDASARKAN SKENARIO\".center(80))\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "        # Define scenarios\n",
    "        scenarios = [\n",
    "            {\"name\": \"Jarak Dekat (< 7m)\", \"filter_key\": \"distance_m\", \"condition\": lambda x: x < 7},\n",
    "            {\"name\": \"Jarak Menengah (7-12m)\", \"filter_key\": \"distance_m\", \"condition\": lambda x: 7 <= x < 12},\n",
    "            {\"name\": \"Jarak Jauh (>= 12m)\", \"filter_key\": \"distance_m\", \"condition\": lambda x: x >= 12},\n",
    "            {\"name\": \"Ketinggian 1.5m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 1.5},\n",
    "            {\"name\": \"Ketinggian 3m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 3},\n",
    "            {\"name\": \"Ketinggian 4m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 4},\n",
    "            {\"name\": \"Ketinggian 5m\", \"filter_key\": \"height_m\", \"condition\": lambda x: x == 5},\n",
    "            {\"name\": \"Semua Data Uji\", \"filter_key\": None, \"condition\": None}\n",
    "        ]\n",
    "\n",
    "        # Create separate tables for each model\n",
    "        models = ['knn', 'svm', 'cosine']\n",
    "        model_names = {\n",
    "            'knn': 'K-Nearest Neighbors (KNN)',\n",
    "            'svm': 'Support Vector Machine (SVM)',\n",
    "            'cosine': 'Cosine Similarity'\n",
    "        }\n",
    "\n",
    "        all_tables = {}\n",
    "\n",
    "        for model in models:\n",
    "            comparison_data = []\n",
    "\n",
    "            for scenario in scenarios:\n",
    "                scenario_name = scenario[\"name\"]\n",
    "\n",
    "                # =========================================================\n",
    "                # LOGIKA FILTERING (FIX NAME ERROR)\n",
    "                # =========================================================\n",
    "                if scenario[\"filter_key\"] is None:\n",
    "                    # Semua data\n",
    "                    filtered_orig = df_original\n",
    "                    filtered_rest = df_restored\n",
    "                else:\n",
    "                    filter_key = scenario[\"filter_key\"]\n",
    "                    condition = scenario[\"condition\"]\n",
    "                    \n",
    "                    # Filter Original\n",
    "                    if not df_original.empty:\n",
    "                        filtered_orig = df_original[\n",
    "                            df_original[filter_key].notna() & \n",
    "                            df_original[filter_key].apply(condition)\n",
    "                        ]\n",
    "                    else:\n",
    "                        filtered_orig = pd.DataFrame()\n",
    "                        \n",
    "                    # Filter Restored\n",
    "                    if not df_restored.empty:\n",
    "                        filtered_rest = df_restored[\n",
    "                            df_restored[filter_key].notna() & \n",
    "                            df_restored[filter_key].apply(condition)\n",
    "                        ]\n",
    "                    else:\n",
    "                        filtered_rest = pd.DataFrame()\n",
    "                # =========================================================\n",
    "\n",
    "                # Calculate metrics untuk ORIGINAL\n",
    "                if not filtered_orig.empty:\n",
    "                    labels_scenario = sorted(filtered_orig['ground_truth'].unique())\n",
    "                    metrics_orig = calculate_metrics(filtered_orig, '_original', labels_scenario)\n",
    "\n",
    "                    if model in metrics_orig:\n",
    "                        acc_orig = metrics_orig[model]['accuracy']\n",
    "                        prec_orig = metrics_orig[model]['precision']\n",
    "                        rec_orig = metrics_orig[model]['recall']\n",
    "                        f1_orig = metrics_orig[model]['f1']\n",
    "\n",
    "                        comparison_data.append([\n",
    "                            scenario_name,\n",
    "                            'Tanpa Restorasi',\n",
    "                            f'{acc_orig:.2%}',   # Format Persen\n",
    "                            f'{prec_orig:.2%}',  # Format Persen\n",
    "                            f'{rec_orig:.2%}',   # Format Persen\n",
    "                            f'{f1_orig:.2%}',    # Format Persen\n",
    "                            '-'\n",
    "                        ])\n",
    "                else:\n",
    "                    comparison_data.append([scenario_name, 'Tanpa Restorasi', 'N/A', 'N/A', 'N/A', 'N/A', '-'])\n",
    "\n",
    "                # Calculate metrics untuk RESTORED\n",
    "                if not filtered_rest.empty:\n",
    "                    labels_scenario = sorted(filtered_rest['ground_truth'].unique())\n",
    "                    metrics_rest = calculate_metrics(filtered_rest, '_restored', labels_scenario)\n",
    "\n",
    "                    if model in metrics_rest:\n",
    "                        acc_rest = metrics_rest[model]['accuracy']\n",
    "                        prec_rest = metrics_rest[model]['precision']\n",
    "                        rec_rest = metrics_rest[model]['recall']\n",
    "                        f1_rest = metrics_rest[model]['f1']\n",
    "\n",
    "                        # Calculate improvement\n",
    "                        if not filtered_orig.empty and model in metrics_orig:\n",
    "                            acc_orig = metrics_orig[model]['accuracy']\n",
    "                            improvement = ((acc_rest - acc_orig) / acc_orig * 100) if acc_orig > 0 else 0\n",
    "                            improvement_str = f'{improvement:+.2f}%'\n",
    "                        else:\n",
    "                            improvement_str = 'N/A'\n",
    "\n",
    "                        comparison_data.append([\n",
    "                            scenario_name,\n",
    "                            'Dengan Restorasi',\n",
    "                            f'{acc_rest:.2%}',   # Format Persen\n",
    "                            f'{prec_rest:.2%}',  # Format Persen\n",
    "                            f'{rec_rest:.2%}',   # Format Persen\n",
    "                            f'{f1_rest:.2%}',    # Format Persen\n",
    "                            improvement_str\n",
    "                        ])\n",
    "                else:\n",
    "                    comparison_data.append([scenario_name, 'Dengan Restorasi', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'])\n",
    "\n",
    "            all_tables[model] = comparison_data\n",
    "\n",
    "        # >>>>> TAMPILKAN TABEL <<<<<\n",
    "        columns = ['Skenario', 'Metode', 'Akurasi (Top-1)', 'Presisi', 'Recall', 'F1-Score', 'Peningkatan Akurasi']\n",
    "\n",
    "        for model in models:\n",
    "            if all_tables[model]:\n",
    "                table_df = pd.DataFrame(all_tables[model], columns=columns)\n",
    "                print(f\"\\n{'='*120}\")\n",
    "                print(f\"Tabel Perbandingan Kinerja - {model_names[model]}\".center(120))\n",
    "                print(f\"{'='*120}\")\n",
    "                print(table_df.to_string(index=False))\n",
    "                print(f\"{'='*120}\\n\")\n",
    "\n",
    "                try:\n",
    "                    csv_path = os.path.join(RESULTS_PATH, f'comparison_table_{model}_v6.4.3.2.csv')\n",
    "                    table_df.to_csv(csv_path, index=False)\n",
    "                    print(f\"Tabel {model_names[model]} disimpan ke: {csv_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Gagal menyimpan tabel {model}: {e}\")\n",
    "\n",
    "        # >>>>> BAGIAN 3: SUMMARY STATISTIK <<<<<\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"BAGIAN 3: SUMMARY PENINGKATAN KINERJA\".center(80))\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "        if not df_original.empty and not df_restored.empty:\n",
    "            common_labels = sorted(set(df_original['ground_truth'].unique()) & set(df_restored['ground_truth'].unique()))\n",
    "            if common_labels:\n",
    "                overall_orig = calculate_metrics(df_original, '_original', common_labels)\n",
    "                overall_rest = calculate_metrics(df_restored, '_restored', common_labels)\n",
    "\n",
    "                summary_data = []\n",
    "                for model in models:\n",
    "                    if model in overall_orig and model in overall_rest:\n",
    "                        acc_orig = overall_orig[model]['accuracy']\n",
    "                        acc_rest = overall_rest[model]['accuracy']\n",
    "                        improvement = ((acc_rest - acc_orig) / acc_orig * 100) if acc_orig > 0 else 0\n",
    "\n",
    "                        summary_data.append([\n",
    "                            model_names[model],\n",
    "                            f'{acc_orig:.2%}',\n",
    "                            f'{acc_rest:.2%}',\n",
    "                            f'{improvement:+.1f}%'\n",
    "                        ])\n",
    "\n",
    "                if summary_data:\n",
    "                    summary_df = pd.DataFrame(summary_data, columns=['Model', 'Akurasi Original', 'Akurasi Restored', 'Peningkatan'])\n",
    "                    print(summary_df.to_string(index=False))\n",
    "                    print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "                    try:\n",
    "                        summary_path = os.path.join(RESULTS_PATH, 'summary_improvement_v3.csv')\n",
    "                        summary_df.to_csv(summary_path, index=False)\n",
    "                        print(f\"Summary peningkatan disimpan ke: {summary_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Gagal menyimpan summary: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALISIS SELESAI\".center(80))\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
